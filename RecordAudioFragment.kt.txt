package com.example.mexicoparanormal

import android.Manifest
import android.annotation.SuppressLint
import android.content.ContentValues
import android.content.Context
import android.content.Intent
import android.content.pm.PackageManager
import android.media.AudioFormat // Para decodificación PCM
import android.media.MediaCodec // Para decodificación y CODIFICACIÓN
import android.media.MediaCodecInfo
import android.media.MediaExtractor // Para decodificación
import android.media.MediaFormat as AndroidMediaFormat // Alias para MediaFormat de Android
import android.media.MediaMetadataRetriever
import android.media.MediaMuxer // Para escribir el archivo M4A
import android.media.MediaRecorder
import android.media.MediaScannerConnection
import android.net.Uri
import android.os.Build
import android.os.Bundle
import android.os.Environment
import android.os.Handler
import android.os.Looper
import android.os.StatFs
import android.provider.MediaStore
import android.provider.Settings
import android.util.Log
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.AdapterView
import android.widget.ArrayAdapter
import android.widget.SeekBar
import android.widget.Toast
import androidx.activity.result.contract.ActivityResultContracts
import androidx.appcompat.app.AlertDialog
import androidx.core.content.ContextCompat
import androidx.core.net.toUri
import androidx.fragment.app.Fragment
import androidx.lifecycle.lifecycleScope
import com.example.mexicoparanormal.databinding.FragmentRecordAudioBinding
import com.google.android.exoplayer2.ExoPlayer
import com.google.android.exoplayer2.MediaItem
import com.google.android.exoplayer2.PlaybackException
import com.google.android.exoplayer2.PlaybackParameters
import com.google.android.exoplayer2.Player
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.currentCoroutineContext
import kotlinx.coroutines.isActive
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import java.io.File
import java.io.FileInputStream
import java.io.FileOutputStream
import java.io.IOException
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.FloatBuffer
import java.nio.ShortBuffer
import java.text.SimpleDateFormat
import java.util.Date
import java.util.Locale
import java.util.Optional // Importado para Optional<OnnxValue>
import java.util.concurrent.TimeUnit
import kotlin.math.abs
import kotlin.math.cos
import kotlin.math.floor
import kotlin.math.min
import kotlin.math.roundToInt


import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession
import ai.onnxruntime.OrtLoggingLevel
import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OnnxValue // Importar OnnxValue
import ai.onnxruntime.OrtSession.Result as OrtResult // Alias para el Resultado de ONNX
import ai.onnxruntime.OrtException // Importar OrtException para errores de ONNX

@Suppress("DEPRECATION") // Para MediaRecorder en APIs antiguas
class RecordAudioFragment : Fragment() {

    private var _binding: FragmentRecordAudioBinding? = null
    private val binding get() = _binding!!

    private var mediaRecorder: MediaRecorder? = null
    private var audioFile: File? = null // Archivo M4A original grabado
    private var processedAudioFile: File? = null // Archivo M4A final (potencialmente procesado por IA)
    private var currentRecordingState: RecordingState = RecordingState.IDLE
    private var selectedAudioSourceType: AudioSourceType = AudioSourceType.MIC_NORMAL

    private var exoPlayer: ExoPlayer? = null
    private var currentPlayableAudioUri: Uri? = null
    private var currentPlayableAudioOriginalName: String? = null

    private val playbackSpeeds = floatArrayOf(0.5f, 1.0f, 1.5f, 2.0f)
    private lateinit var playbackSpeedStrings: Array<String> // Se inicializa en onViewCreated
    private var currentSpeedIndex = 1 // Índice para 1.0x

    private var playerPlaybackPosition: Long = 0
    private var playerPlayWhenReady: Boolean = true

    private var recordingChronometer: Long = 0L
    private val recordingTimerHandler = Handler(Looper.getMainLooper())
    private lateinit var recordingTimerRunnable: Runnable
    private val MAX_RECORDING_DURATION_MS: Long = 20 * 60 * 1000 // 20 minutos
    private val ESTIMATED_MAX_RECORDING_SIZE_BYTES: Long = 25 * 1024 * 1024 // Estimación conservadora para M4A/AAC
    private val STORAGE_MARGIN_BYTES: Long = 30 * 1024 * 1024 // Margen extra para archivos temporales PCM

    private val seekBarUpdateHandler = Handler(Looper.getMainLooper())
    private lateinit var runnableUpdateSeekBar: Runnable

    private var currentToast: Toast? = null

    private lateinit var waveformView: WaveformView
    private val amplitudeUpdateHandler = Handler(Looper.getMainLooper())
    private lateinit var amplitudeUpdater: Runnable
    private val AMPLITUDE_UPDATE_INTERVAL_MS: Long = 100

    // Relacionado con ONNX Runtime
    private var ortEnvironment: OrtEnvironment? = null
    private var encSession: OrtSession? = null
    private var dfDecSession: OrtSession? = null
    private var erbDecSession: OrtSession? = null

    // Nombres de archivo para modelos ONNX (constantes internas)
    private val ENC_MODEL_FILE_NAME = "enc.onnx"
    private val DF_DEC_MODEL_FILE_NAME = "df_dec.onnx"
    private val ERB_DEC_MODEL_FILE_NAME = "erb_dec.onnx"

    // Nombres de archivo para archivos temporales (constantes internas)
    private val DECODED_AUDIO_FOR_AI_FILENAME = "decoded_audio_for_ai.pcm"
    private val FINAL_PCM_FOR_ONNX_INPUT_FILENAME = "final_pcm_for_onnx_input.pcm"
    private val ONNX_PROCESSED_AUDIO_OUTPUT_FILENAME = "onnx_processed_audio_output.pcm"
    private val IA_PROCESSED_FILENAME_PREFIX = "IA_processed_"


    private var isAiFeatureNoticeShown = false
    private var aiProcessingJob: Job? = null

    // Constantes para el procesamiento de audio IA
    private val TARGET_SAMPLE_RATE_HZ = 48000 // Frecuencia de muestreo objetivo para la IA y la salida
    private val TARGET_CHANNEL_COUNT = 1 // Mono
    private val TARGET_AUDIO_ENCODING_ANDROID = AudioFormat.ENCODING_PCM_16BIT // PCM 16-bit para procesamiento

    // Parámetros STFT (del config.ini de DeepFilterNet)
    private val DFN_STFT_FFT_SIZE = 960
    private val DFN_STFT_HOP_SIZE = 480 // Este es el importante para calcular el número de tramas (S)

    private val AAC_MIME_TYPE = "audio/mp4a-latm"
    private val AAC_BIT_RATE = 128000 // Bitrate para la codificación AAC


    interface AudioRecordListener {
        fun onAudioRecorded(uri: Uri?, originalFileName: String?)
        fun onRecordingStateChanged(isRecording: Boolean)
        fun onAudioDeleted()
    }
    private var listener: AudioRecordListener? = null

    private enum class RecordingState {
        IDLE, RECORDING, PAUSED, STOPPED, AI_PROCESSING
    }

    private enum class AudioSourceType {
        MIC_NORMAL,
        MIC_AI_ENHANCED
        // Futuro: MIC_VOICE_OPTIMIZED, SYSTEM_AUDIO (Audio del sistema)
    }

    private val requestRecordAudioPermissionLauncher =
        registerForActivityResult(ActivityResultContracts.RequestPermission()) { isGranted: Boolean ->
            if (isGranted) {
                startRecordingFlow()
            } else {
                if (!shouldShowRequestPermissionRationale(Manifest.permission.RECORD_AUDIO) && currentRecordingState != RecordingState.IDLE) {
                    showSafeToast(getString(R.string.error_mic_permission_denied_permanently), Toast.LENGTH_LONG)
                    promptToOpenSettings()
                } else {
                    showSafeToast(getString(R.string.error_mic_permission_denied), Toast.LENGTH_LONG)
                }
                updateUI()
            }
        }

    private val requestWriteStoragePermissionLauncher =
        registerForActivityResult(ActivityResultContracts.RequestPermission()) { isGranted: Boolean ->
            if (isGranted) {
                currentPlayableAudioUri?.let { uri ->
                    val nameToSave = currentPlayableAudioOriginalName ?: getString(R.string.default_filename_unknown_m4a)
                    saveAudioToPublicMusicDirectory(uri, nameToSave)
                }
            } else {
                showSafeToast(getString(R.string.error_write_permission_denied_for_saving))
            }
        }

    override fun onAttach(context: Context) {
        super.onAttach(context)
        listener = context as? AudioRecordListener ?: throw ClassCastException(getString(R.string.error_listener_not_implemented_audiorecord, context.toString()))
    }

    override fun onCreateView(
        inflater: LayoutInflater, container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View {
        _binding = FragmentRecordAudioBinding.inflate(inflater, container, false)
        waveformView = binding.waveformView
        return binding.root
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)
        setupPlaybackSpeedStrings()
        setupAudioSourceSpinner()
        setupClickListeners()
        initializeRecordingTimerRunnable()
        initializeAmplitudeUpdater()
        initializeSeekBarUpdaterPlayer()
        initializeOnnxRuntime() // Carga los modelos ONNX

        // Restaurar estado si existe
        savedInstanceState?.let {
            currentRecordingState = RecordingState.valueOf(it.getString("recordingState", RecordingState.IDLE.name))
            selectedAudioSourceType = AudioSourceType.valueOf(it.getString("selectedAudioSourceType", AudioSourceType.MIC_NORMAL.name))
            recordingChronometer = it.getLong("recordingChronometer", 0L)
            it.getString("audioFilePath")?.let { path -> audioFile = File(path) }
            it.getString("processedAudioFilePath")?.let { path -> processedAudioFile = File(path) }
            it.getString("currentPlayableAudioUri")?.let { uriString -> currentPlayableAudioUri = uriString.toUri() }
            currentPlayableAudioOriginalName = it.getString("currentPlayableAudioOriginalName")
            playerPlaybackPosition = it.getLong("playerPlaybackPosition", 0L)
            playerPlayWhenReady = it.getBoolean("playerPlayWhenReady", true)
            currentSpeedIndex = it.getInt("currentSpeedIndex", 1)
            isAiFeatureNoticeShown = it.getBoolean("isAiFeatureNoticeShown", false)
        }
        updateUI() // Actualizar UI basado en el estado (restaurado o inicial)
    }

    private fun loadOnnxModel(modelFileName: String): OrtSession? {
        if (context == null || ortEnvironment == null) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_load_onnx_context_null, modelFileName))
            return null
        }
        return try {
            val modelFileInCache = File(requireContext().cacheDir, modelFileName)
            if (!modelFileInCache.exists()) {
                requireContext().assets.open(modelFileName).use { inputStream ->
                    FileOutputStream(modelFileInCache).use { outputStream ->
                        inputStream.copyTo(outputStream)
                    }
                }
                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_info_onnx_model_copied_to_cache, modelFileName, modelFileInCache.absolutePath))
            } else {
                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_info_onnx_model_exists_in_cache, modelFileName, modelFileInCache.absolutePath))
            }
            ortEnvironment!!.createSession(modelFileInCache.absolutePath, OrtSession.SessionOptions())
        } catch (e: IOException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_onnx_ioexception, modelFileName), e)
            null
        } catch (e: OrtException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_onnx_ortexception, modelFileName), e)
            null
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_onnx_unexpected, modelFileName), e)
            null
        }
    }

    private fun initializeOnnxRuntime() {
        if (!isAdded || context == null) return
        lifecycleScope.launch(Dispatchers.IO) {
            try {
                ortEnvironment = OrtEnvironment.getEnvironment(OrtLoggingLevel.ORT_LOGGING_LEVEL_WARNING)
                encSession = loadOnnxModel(ENC_MODEL_FILE_NAME)
                dfDecSession = loadOnnxModel(DF_DEC_MODEL_FILE_NAME)
                erbDecSession = loadOnnxModel(ERB_DEC_MODEL_FILE_NAME)

                withContext(Dispatchers.Main) {
                    if (!isAdded) return@withContext
                    if (encSession != null && dfDecSession != null && erbDecSession != null) {
                        Log.i(TAG_RECORD_AUDIO, getString(R.string.log_info_onnx_models_loaded_successfully))
                    } else {
                        Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_onnx_failed_to_load_models))
                        showSafeToast(getString(R.string.error_critical_ai_initialization), Toast.LENGTH_LONG)
                    }
                }
            } catch (e: OrtException) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_onnx_ortexception_init), e)
                withContext(Dispatchers.Main) { if (isAdded) showSafeToast(getString(R.string.error_critical_ai_initialization_ort), Toast.LENGTH_LONG) }
            } catch (e: Exception) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_onnx_critical_init), e)
                withContext(Dispatchers.Main) { if (isAdded) showSafeToast(getString(R.string.error_critical_ai_initialization), Toast.LENGTH_LONG) }
            }
        }
    }


    override fun onResume() {
        super.onResume()
        if (currentPlayableAudioUri != null && currentRecordingState != RecordingState.AI_PROCESSING) {
            if (exoPlayer == null) {
                initializePlayer(currentPlayableAudioUri!!)
            } else {
                exoPlayer?.seekTo(playerPlaybackPosition)
                if (playerPlayWhenReady && exoPlayer?.playbackState != Player.STATE_ENDED) {
                    exoPlayer?.play()
                }
            }
            updatePlayerUI()
        } else if (currentRecordingState != RecordingState.AI_PROCESSING) {
            updateUI()
            if(::waveformView.isInitialized) waveformView.clearWaveform()
        }

        if (currentRecordingState == RecordingState.RECORDING) {
            amplitudeUpdateHandler.post(amplitudeUpdater)
        }
    }

    override fun onPause() {
        super.onPause()
        currentToast?.cancel()

        if (::runnableUpdateSeekBar.isInitialized) {
            seekBarUpdateHandler.removeCallbacks(runnableUpdateSeekBar)
        }

        exoPlayer?.let {
            playerPlaybackPosition = it.currentPosition
            playerPlayWhenReady = it.playWhenReady
            it.pause()
        }

        if (currentRecordingState == RecordingState.RECORDING) {
            amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
        }
    }

    override fun onStop() {
        super.onStop()
        if ((currentRecordingState == RecordingState.RECORDING || currentRecordingState == RecordingState.PAUSED) && mediaRecorder != null) {
            amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
            stopRecordingFlow(bySystem = true, message = getString(R.string.info_recording_stopped_due_to_app_state))
        }
    }

    override fun onSaveInstanceState(outState: Bundle) {
        super.onSaveInstanceState(outState)
        outState.putString("recordingState", currentRecordingState.name)
        outState.putString("selectedAudioSourceType", selectedAudioSourceType.name)
        outState.putLong("recordingChronometer", recordingChronometer)
        audioFile?.absolutePath?.let { outState.putString("audioFilePath", it) }
        processedAudioFile?.absolutePath?.let { outState.putString("processedAudioFilePath", it) }
        currentPlayableAudioUri?.toString()?.let { outState.putString("currentPlayableAudioUri", it) }
        outState.putString("currentPlayableAudioOriginalName", currentPlayableAudioOriginalName)
        exoPlayer?.let {
            outState.putLong("playerPlaybackPosition", it.currentPosition)
            outState.putBoolean("playerPlayWhenReady", it.playWhenReady)
        }
        outState.putInt("currentSpeedIndex", currentSpeedIndex)
        outState.putBoolean("isAiFeatureNoticeShown", isAiFeatureNoticeShown)
    }

    override fun onDestroyView() {
        super.onDestroyView()
        recordingTimerHandler.removeCallbacks(recordingTimerRunnable)
        amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
        releaseMediaRecorder()
        releasePlayer()
        aiProcessingJob?.cancel()

        try {
            encSession?.close()
            dfDecSession?.close()
            erbDecSession?.close()
            ortEnvironment?.close()
            Log.d(TAG_RECORD_AUDIO, getString(R.string.log_onnx_resources_closed_successfully))
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_onnx_resources_error_closing), e)
        }
        encSession = null
        dfDecSession = null
        erbDecSession = null
        ortEnvironment = null

        currentToast?.cancel()
        _binding = null
    }

    override fun onDetach() {
        super.onDetach()
        listener = null
    }

    private fun showSafeToast(message: String, duration: Int = Toast.LENGTH_SHORT) {
        if(isAdded && context != null) {
            currentToast?.cancel()
            currentToast = Toast.makeText(requireContext(), message, duration)
            currentToast?.show()
        }
    }

    private fun showAlertDialog(title: String, message: String) {
        if (!isAdded) return
        AlertDialog.Builder(requireContext())
            .setTitle(title)
            .setMessage(message)
            .setPositiveButton(getString(R.string.dialog_ok), null)
            .show()
    }

    private fun promptToOpenSettings() {
        if (!isAdded) return
        AlertDialog.Builder(requireContext())
            .setTitle(getString(R.string.permission_dialog_title))
            .setMessage(getString(R.string.error_mic_permission_denied_permanently_prompt))
            .setPositiveButton(getString(R.string.action_open_settings)) { _, _ ->
                val intent = Intent(Settings.ACTION_APPLICATION_DETAILS_SETTINGS).apply {
                    data = Uri.fromParts("package", requireActivity().packageName, null)
                }
                startActivity(intent)
            }
            .setNegativeButton(getString(R.string.cancelar), null)
            .show()
    }

    private fun setupPlaybackSpeedStrings() {
        // Los valores como "0.5x" se mantienen, "1x" se obtiene de resources
        playbackSpeedStrings = arrayOf("0.5x", getString(R.string.text_playback_speed_1x), "1.5x", "2x")
    }

    private fun setupAudioSourceSpinner() {
        val sources = listOf(
            getString(R.string.audio_source_mic),
            getString(R.string.audio_source_mic_ai)
        )
        val adapter = ArrayAdapter(requireContext(), R.layout.spinner_item, sources).apply {
            setDropDownViewResource(R.layout.spinner_dropdown_item)
        }
        binding.spinnerAudioSource.adapter = adapter
        binding.spinnerAudioSource.setSelection(0) // Por defecto Micrófono Clásico

        binding.spinnerAudioSource.onItemSelectedListener = object : AdapterView.OnItemSelectedListener {
            override fun onItemSelected(parent: AdapterView<*>?, view: View?, position: Int, id: Long) {
                selectedAudioSourceType = when (position) {
                    1 -> AudioSourceType.MIC_AI_ENHANCED
                    else -> AudioSourceType.MIC_NORMAL
                }
                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_audio_source_selected, selectedAudioSourceType.name))

                if (selectedAudioSourceType == AudioSourceType.MIC_AI_ENHANCED && !isAiFeatureNoticeShown && isAdded) {
                    if (encSession == null || dfDecSession == null || erbDecSession == null) {
                        showAlertDialog(getString(R.string.audio_source_mic_ai), getString(R.string.error_critical_ai_initialization))
                    } else {
                        AlertDialog.Builder(requireContext())
                            .setTitle(getString(R.string.audio_source_mic_ai)) // Título para el diálogo de IA
                            .setMessage(getString(R.string.info_ai_feature_experimental))
                            .setPositiveButton(getString(R.string.dialog_ok)) { _, _ -> isAiFeatureNoticeShown = true }
                            .setCancelable(false)
                            .show()
                    }
                }
            }
            override fun onNothingSelected(parent: AdapterView<*>?) {
                selectedAudioSourceType = AudioSourceType.MIC_NORMAL // Volver a por defecto
            }
        }
    }

    private fun setupClickListeners() {
        binding.btnStartStopRecording.setOnClickListener {
            if (currentRecordingState == RecordingState.AI_PROCESSING) {
                showSafeToast(getString(R.string.info_ai_processing_audio))
                return@setOnClickListener
            }

            if (selectedAudioSourceType == AudioSourceType.MIC_AI_ENHANCED && (encSession == null || dfDecSession == null || erbDecSession == null)) {
                showAlertDialog(getString(R.string.audio_source_mic_ai), getString(R.string.error_critical_ai_initialization))
                return@setOnClickListener
            }

            when (currentRecordingState) {
                RecordingState.IDLE, RecordingState.STOPPED -> {
                    when {
                        ContextCompat.checkSelfPermission(requireContext(), Manifest.permission.RECORD_AUDIO) == PackageManager.PERMISSION_GRANTED -> {
                            startRecordingFlow()
                        }
                        shouldShowRequestPermissionRationale(Manifest.permission.RECORD_AUDIO) -> {
                            AlertDialog.Builder(requireContext())
                                .setTitle(getString(R.string.permission_dialog_title))
                                .setMessage(getString(R.string.permission_dialog_mic_rationale))
                                .setPositiveButton(getString(R.string.permission_dialog_grant)) { _, _ ->
                                    requestRecordAudioPermissionLauncher.launch(Manifest.permission.RECORD_AUDIO)
                                }
                                .setNegativeButton(getString(R.string.cancelar), null)
                                .show()
                        }
                        else -> {
                            requestRecordAudioPermissionLauncher.launch(Manifest.permission.RECORD_AUDIO)
                        }
                    }
                }
                RecordingState.RECORDING, RecordingState.PAUSED -> {
                    stopRecordingFlow()
                }
                else -> { /* No hacer nada para AI_PROCESSING aquí, ya se maneja arriba */ }
            }
        }

        binding.btnPauseResumeRecording.setOnClickListener {
            if (currentRecordingState == RecordingState.RECORDING) {
                pauseRecordingFlow()
            } else if (currentRecordingState == RecordingState.PAUSED) {
                resumeRecordingFlow()
            }
        }

        binding.btnPlayRecordedAudio.setOnClickListener { exoPlayer?.play() }
        binding.btnPauseRecordedAudio.setOnClickListener { exoPlayer?.pause() }
        binding.btnDeleteRecordedAudio.setOnClickListener { deleteRecordedAudio() }
        binding.tvPlaybackSpeedRecorded.setOnClickListener { cyclePlaybackSpeed() }

        binding.btnSaveLocalAudio?.setOnClickListener {
            currentPlayableAudioUri?.let { uri ->
                val nameToSave = currentPlayableAudioOriginalName ?: getString(R.string.default_filename_unknown_m4a)
                saveAudioToPublicMusicDirectory(uri, nameToSave)
            } ?: showSafeToast(getString(R.string.info_no_recording_to_save))
        }

        binding.seekBarRecordedAudio.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener {
            override fun onProgressChanged(seekBar: SeekBar?, progress: Int, fromUser: Boolean) {
                if (fromUser && exoPlayer != null) {
                    exoPlayer?.seekTo(progress.toLong())
                }
            }
            override fun onStartTrackingTouch(seekBar: SeekBar?) {}
            override fun onStopTrackingTouch(seekBar: SeekBar?) {}
        })
    }

    private fun hasSufficientStorage(requiredBytes: Long): Boolean {
        if (!isAdded) return false
        val cacheDir = requireContext().cacheDir ?: return false // Usar cacheDir que es más seguro
        return try {
            val stat = StatFs(cacheDir.path)
            val availableBytes = stat.availableBlocksLong * stat.blockSizeLong
            availableBytes > (requiredBytes + STORAGE_MARGIN_BYTES) // Margen de seguridad
        } catch (e: IllegalArgumentException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_check_storage_illegal_arg), e)
            false // Asumir que no hay espacio si hay error
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_error_check_storage_unexpected), e)
            false
        }
    }

    private fun startRecordingFlow() {
        if (!isAdded) return

        if (!hasSufficientStorage(ESTIMATED_MAX_RECORDING_SIZE_BYTES)) {
            showAlertDialog(getString(R.string.error_insufficient_storage_title), getString(R.string.error_insufficient_storage_message))
            return
        }

        if (currentPlayableAudioUri != null) { // Si ya hay una grabación
            AlertDialog.Builder(requireContext())
                .setTitle(getString(R.string.dialog_confirm_new_recording_title))
                .setMessage(getString(R.string.dialog_confirm_new_recording_message))
                .setPositiveButton(getString(R.string.dialog_yes)) { _, _ ->
                    deleteRecordedAudio(notifyListener = false) // No notificar al listener aún
                    actuallyStartRecording()
                }
                .setNegativeButton(getString(R.string.dialog_no), null)
                .show()
        } else {
            actuallyStartRecording()
        }
    }

    @SuppressLint("NewApi") // Para MediaRecorder(Context)
    private fun actuallyStartRecording() {
        if (!isAdded || context == null) return

        val rawFileName = "${getString(R.string.file_name_prefix)}${SimpleDateFormat(getString(R.string.file_name_date_format), Locale.getDefault()).format(Date())}${getString(R.string.file_extension_m4a)}"
        val cacheDir = requireContext().cacheDir ?: run {
            handleRecordingStartError(getString(R.string.error_cache_dir_unavailable))
            return
        }

        mediaRecorder = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) MediaRecorder(requireContext()) else @Suppress("DEPRECATION") MediaRecorder()

        mediaRecorder?.apply {
            setAudioSource(MediaRecorder.AudioSource.MIC)
            setOutputFormat(MediaRecorder.OutputFormat.MPEG_4) // Contenedor M4A
            setAudioEncoder(MediaRecorder.AudioEncoder.AAC)   // Códec AAC
            setAudioEncodingBitRate(AAC_BIT_RATE)             // Bitrate para AAC
            setAudioChannels(TARGET_CHANNEL_COUNT)            // Mono

            // Intentar establecer la frecuencia de muestreo deseada
            try {
                setAudioSamplingRate(TARGET_SAMPLE_RATE_HZ)
                Log.i(TAG_RECORD_AUDIO, getString(R.string.log_mediarecorder_configured_at_samplerate, TARGET_SAMPLE_RATE_HZ))
            } catch (e: Exception) {
                Log.w(TAG_RECORD_AUDIO, getString(R.string.log_mediarecorder_failed_to_set_samplerate_fallback, TARGET_SAMPLE_RATE_HZ), e)
                setAudioSamplingRate(44100) // Fallback a 44.1kHz si falla
            }

            audioFile = File(cacheDir, rawFileName)
            currentPlayableAudioOriginalName = rawFileName // Guardar nombre original para UI
            setOutputFile(audioFile!!.absolutePath)
            setMaxDuration(MAX_RECORDING_DURATION_MS.toInt() + 1000) // Un pequeño margen

            setOnErrorListener { mr, what, extra ->
                amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
                val errorMsg = when(what) {
                    MediaRecorder.MEDIA_RECORDER_ERROR_UNKNOWN -> getString(R.string.error_media_recorder_unknown)
                    MediaRecorder.MEDIA_ERROR_SERVER_DIED -> getString(R.string.error_media_server_died)
                    else -> getString(R.string.error_start_recording_with_code, what, extra)
                }
                Log.e(TAG_RECORD_AUDIO, "MediaRecorder.OnErrorListener: what=$what, extra=$extra, message='$errorMsg'")
                stopRecordingFlow(bySystem = true, message = errorMsg)
            }
            setOnInfoListener { mr, what, extra ->
                if (what == MediaRecorder.MEDIA_RECORDER_INFO_MAX_DURATION_REACHED) {
                    amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
                    stopRecordingFlow(bySystem = false, message = getString(R.string.info_max_duration_reached, MAX_RECORDING_DURATION_MS / (60 * 1000)))
                }
            }

            try {
                prepare()
                start()
                currentRecordingState = RecordingState.RECORDING
                recordingChronometer = 0L // Reiniciar cronómetro
                binding.tvRecordingTimer.text = formatDuration(0L, MAX_RECORDING_DURATION_MS, currentRecordingState, true)
                recordingTimerHandler.post(recordingTimerRunnable)
                if(::waveformView.isInitialized) waveformView.clearWaveform() // Limpiar forma de onda
                amplitudeUpdateHandler.post(amplitudeUpdater) // Iniciar actualizador de amplitud
                listener?.onRecordingStateChanged(isRecording = true)
                updateUI()
                showSafeToast(getString(R.string.recording_status_recording))
            } catch (ioe: IOException) {
                Log.e(TAG_RECORD_AUDIO, "IOException durante prepare/start de MediaRecorder.", ioe)
                handleRecordingStartError(getString(R.string.error_media_recorder_prepare_io, ioe.localizedMessage ?: getString(R.string.unknown_error)))
            } catch (ise: IllegalStateException) {
                Log.e(TAG_RECORD_AUDIO, "IllegalStateException durante prepare/start de MediaRecorder.", ise)
                handleRecordingStartError(getString(R.string.error_media_recorder_start_state, ise.localizedMessage ?: getString(R.string.unknown_error)))
            } catch (se: SecurityException) { // Aunque ya se verifica el permiso, por si acaso
                Log.e(TAG_RECORD_AUDIO, "SecurityException durante prepare/start de MediaRecorder.", se)
                handleRecordingStartError(getString(R.string.error_mic_permission_denied) + " (SecurityException)")
            } catch (e: Exception) { // Captura genérica
                Log.e(TAG_RECORD_AUDIO, "Excepción inesperada durante prepare/start de MediaRecorder.", e)
                handleRecordingStartError(getString(R.string.error_start_recording_generic, e.localizedMessage ?: getString(R.string.unknown_error)))
            }
        }
    }

    private fun handleRecordingStartError(errorMessage: String) {
        releaseMediaRecorder()
        amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
        currentRecordingState = RecordingState.IDLE
        listener?.onRecordingStateChanged(isRecording = false)
        updateUI()
        showAlertDialog(getString(R.string.error_dialog_title), errorMessage)
    }

    @SuppressLint("NewApi") // Para MediaRecorder.pause/resume
    private fun pauseRecordingFlow() {
        if (currentRecordingState != RecordingState.RECORDING || mediaRecorder == null) return
        try {
            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.N) {
                mediaRecorder?.pause()
                currentRecordingState = RecordingState.PAUSED
                recordingTimerHandler.removeCallbacks(recordingTimerRunnable) // Detener cronómetro
                amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater) // Detener actualización de amplitud
                updateUI()
                showSafeToast(getString(R.string.recording_paused_status))
            } else {
                showSafeToast(getString(R.string.error_pause_not_supported))
            }
        } catch (e: IllegalStateException) {
            Log.e(TAG_RECORD_AUDIO, "IllegalStateException al pausar MediaRecorder.", e)
            showSafeToast(getString(R.string.error_pause_recording_specific, e.localizedMessage ?: getString(R.string.unknown_error)))
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, "Error inesperado al pausar MediaRecorder.", e)
            showSafeToast(getString(R.string.error_pause_recording_specific, e.localizedMessage ?: getString(R.string.unknown_error)))
        }
    }

    @SuppressLint("NewApi") // Para MediaRecorder.pause/resume
    private fun resumeRecordingFlow() {
        if (currentRecordingState != RecordingState.PAUSED || mediaRecorder == null) return
        try {
            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.N) {
                mediaRecorder?.resume()
                currentRecordingState = RecordingState.RECORDING
                recordingTimerHandler.post(recordingTimerRunnable) // Reanudar cronómetro
                amplitudeUpdateHandler.post(amplitudeUpdater) // Reanudar actualización de amplitud
                updateUI()
                showSafeToast(getString(R.string.recording_status_recording)) // Reutilizar string
            }
        } catch (e: IllegalStateException) {
            Log.e(TAG_RECORD_AUDIO, "IllegalStateException al reanudar MediaRecorder.", e)
            showSafeToast(getString(R.string.error_resume_recording_specific, e.localizedMessage ?: getString(R.string.unknown_error)))
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, "Error inesperado al reanudar MediaRecorder.", e)
            showSafeToast(getString(R.string.error_resume_recording_specific, e.localizedMessage ?: getString(R.string.unknown_error)))
        }
    }

    private fun stopRecordingFlow(bySystem: Boolean = false, message: String? = null) {
        if (currentRecordingState == RecordingState.IDLE && mediaRecorder == null) return // Ya está detenido o nunca empezó

        val previousState = currentRecordingState
        val finalChronometerValue = recordingChronometer // Guardar valor antes de resetear

        recordingTimerHandler.removeCallbacks(recordingTimerRunnable)
        amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)

        var stopErrorOccurred = false
        try {
            mediaRecorder?.stop()
        } catch (e: RuntimeException) {
            Log.e(TAG_RECORD_AUDIO, "RuntimeException al detener MediaRecorder.", e)
            stopErrorOccurred = true
        } catch (e: IllegalStateException) {
            Log.e(TAG_RECORD_AUDIO, "IllegalStateException al detener MediaRecorder.", e)
            stopErrorOccurred = true
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, "Error inesperado al detener MediaRecorder.", e)
            stopErrorOccurred = true
        } finally {
            releaseMediaRecorder() // Siempre liberar el grabador

            if (stopErrorOccurred) {
                handleStopError(bySystem, message ?: getString(R.string.error_stop_recording_failed_critical))
            } else if (audioFile?.exists() == true && audioFile!!.length() > 0) {
                // El archivo de audio existe y tiene contenido
                val baseFileName = currentPlayableAudioOriginalName ?: audioFile!!.name // Usar nombre original guardado o el del archivo
                if (selectedAudioSourceType == AudioSourceType.MIC_AI_ENHANCED) {
                    processAudioWithAI(audioFile!!, baseFileName, finalChronometerValue, bySystem, message)
                } else {
                    finalizeRecording(audioFile!!, baseFileName, finalChronometerValue, bySystem, message)
                }
            } else {
                // El archivo no existe o está vacío
                handleStopError(bySystem, message ?: getString(R.string.error_no_audio_recorded_after_stop))
            }

            // Notificar al listener solo si estaba grabando o pausado
            if (previousState == RecordingState.RECORDING || previousState == RecordingState.PAUSED) {
                listener?.onRecordingStateChanged(isRecording = false)
            }
        }
    }

    private fun handleStopError(bySystem: Boolean, errorMessage: String) {
        audioFile?.delete(); audioFile = null
        processedAudioFile?.delete(); processedAudioFile = null
        currentPlayableAudioUri = null; currentPlayableAudioOriginalName = null
        recordingChronometer = 0L // Resetear cronómetro
        if(::waveformView.isInitialized) waveformView.clearWaveform()
        currentRecordingState = RecordingState.STOPPED // Cambiar a STOPPED para reflejar el intento de detener
        updateUI()
        if (!bySystem) { // Mostrar error solo si no fue por el sistema (ej. cambio de app)
            listener?.onAudioRecorded(null, null) // Notificar que no hay audio
            showAlertDialog(getString(R.string.error_dialog_title), errorMessage)
        }
    }

    private fun finalizeRecording(finalAudioFileToUse: File, finalFileNameToUse: String?, durationMs: Long, bySystem: Boolean, message: String?) {
        currentPlayableAudioUri = Uri.fromFile(finalAudioFileToUse)
        currentPlayableAudioOriginalName = finalFileNameToUse
        Log.d(TAG_RECORD_AUDIO, getString(R.string.log_finalize_recording_details, currentPlayableAudioUri.toString(), currentPlayableAudioOriginalName, durationMs.toString()))

        if (isAdded) { // Asegurar que el fragmento está añadido
            currentRecordingState = RecordingState.STOPPED
            initializePlayer(currentPlayableAudioUri!!) // Inicializar reproductor con el audio final
            if (!bySystem) { // Notificar al listener solo si no fue una detención por el sistema
                listener?.onAudioRecorded(currentPlayableAudioUri, currentPlayableAudioOriginalName)
            }
            val toastMessage = message ?: if (!bySystem) getString(R.string.status_finished) else null
            toastMessage?.let { showSafeToast(it, Toast.LENGTH_LONG) }

            // Actualizar temporizador para mostrar duración final
            binding.tvRecordingTimer.text = formatDuration(durationMs, 0L, RecordingState.STOPPED, true)
            updateUI()
        } else {
            Log.w(TAG_RECORD_AUDIO, getString(R.string.log_finalize_recording_fragment_not_attached))
        }
    }

    private fun processAudioWithAI(inputFile: File, baseOutputName: String, durationMs: Long, bySystem: Boolean, originalMessage: String?) {
        if (!isAdded || encSession == null || dfDecSession == null || erbDecSession == null) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_process_audio_with_ai_aborted))
            finalizeRecording(inputFile, baseOutputName, durationMs, bySystem, originalMessage ?: getString(R.string.status_finished)) // Usar audio original
            if (isAdded && (encSession == null || dfDecSession == null || erbDecSession == null)) {
                showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_critical_ai_initialization_sessions))
            }
            return
        }

        currentRecordingState = RecordingState.AI_PROCESSING
        updateUI()
        showSafeToast(getString(R.string.info_ai_processing_audio), Toast.LENGTH_LONG)

        aiProcessingJob = lifecycleScope.launch {
            Log.d(TAG_RECORD_AUDIO, getString(R.string.log_process_audio_with_ai_starting, inputFile.name))

            val enhancedFile = runAiEnhancement(inputFile) // Esta función es suspend

            withContext(Dispatchers.Main) { // Volver al hilo principal para actualizar UI
                if (!isAdded) return@withContext // Comprobar de nuevo si el fragmento está añadido
                aiProcessingJob = null // Limpiar referencia al job
                if (enhancedFile != null) {
                    processedAudioFile = enhancedFile // Guardar referencia al archivo procesado
                    finalizeRecording(enhancedFile, IA_PROCESSED_FILENAME_PREFIX + baseOutputName, durationMs, bySystem, getString(R.string.info_ai_audio_processed))
                } else {
                    // Si el procesamiento IA falla, usar el archivo original
                    showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_ai_processing_failed))
                    finalizeRecording(inputFile, baseOutputName, durationMs, bySystem, originalMessage ?: getString(R.string.status_finished))
                }
            }
        }
    }

    // Estructura de datos para el resultado de la decodificación PCM
    data class PcmAudioData(val file: File, val sampleRate: Int, val channelCount: Int, val bitDepth: Int = 16)

    // Decodifica M4A a PCM crudo
    private suspend fun decodeM4aToPcm(inputFile: File, outputFile: File): PcmAudioData? = withContext(Dispatchers.IO) {
        if (!currentCoroutineContext().isActive || !isAdded || context == null) {
            Log.w(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_coroutine_inactive, inputFile.name))
            return@withContext null
        }
        Log.d(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_starting, inputFile.name, outputFile.name))

        var extractor: MediaExtractor? = null
        var codec: MediaCodec? = null
        var pcmSampleRate = -1
        var pcmChannelCount = -1
        val timeoutUs = 10000L // 10ms

        try {
            extractor = MediaExtractor()
            extractor.setDataSource(inputFile.absolutePath)

            var trackIndex = -1
            var inputFormat: AndroidMediaFormat? = null
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                if (format.getString(AndroidMediaFormat.KEY_MIME)?.startsWith("audio/") == true) {
                    trackIndex = i
                    inputFormat = format
                    break
                }
            }

            if (trackIndex == -1 || inputFormat == null) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_no_audio_track, inputFile.name))
                return@withContext null
            }

            pcmSampleRate = inputFormat.getInteger(AndroidMediaFormat.KEY_SAMPLE_RATE)
            pcmChannelCount = inputFormat.getInteger(AndroidMediaFormat.KEY_CHANNEL_COUNT)
            Log.i(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_input_format, pcmSampleRate.toString(), pcmChannelCount.toString(), inputFile.name))

            extractor.selectTrack(trackIndex)
            val mimeType = inputFormat.getString(AndroidMediaFormat.KEY_MIME)!!
            codec = MediaCodec.createDecoderByType(mimeType)
            codec.configure(inputFormat, null, null, 0)
            codec.start()

            FileOutputStream(outputFile).use { fos ->
                val bufferInfo = MediaCodec.BufferInfo()
                var sawInputEOS = false // Indicador de fin de stream de entrada
                var sawOutputEOS = false // Indicador de fin de stream de salida

                // Bucle de decodificación
                while (!sawOutputEOS && currentCoroutineContext().isActive) {
                    // Alimentar datos al decodificador
                    if (!sawInputEOS) {
                        val inputBufferId = codec.dequeueInputBuffer(timeoutUs)
                        if (inputBufferId >= 0) {
                            val inputBuffer = codec.getInputBuffer(inputBufferId)
                            if (inputBuffer != null) {
                                val sampleSize = extractor.readSampleData(inputBuffer, 0)
                                if (sampleSize < 0) { // Fin del stream
                                    codec.queueInputBuffer(inputBufferId, 0, 0, 0L, MediaCodec.BUFFER_FLAG_END_OF_STREAM)
                                    sawInputEOS = true
                                } else if (sampleSize > 0) {
                                    codec.queueInputBuffer(inputBufferId, 0, sampleSize, extractor.sampleTime, 0)
                                    extractor.advance()
                                } else { // sampleSize == 0, no es EOS pero no hay datos
                                    codec.queueInputBuffer(inputBufferId, 0, 0, extractor.sampleTime, 0)
                                }
                            }
                        }
                    }

                    // Obtener datos decodificados
                    val outputBufferId = codec.dequeueOutputBuffer(bufferInfo, timeoutUs)
                    when (outputBufferId) {
                        MediaCodec.INFO_OUTPUT_FORMAT_CHANGED -> {
                            val newFormat = codec.outputFormat
                            pcmSampleRate = newFormat.getInteger(AndroidMediaFormat.KEY_SAMPLE_RATE)
                            pcmChannelCount = newFormat.getInteger(AndroidMediaFormat.KEY_CHANNEL_COUNT)
                            Log.i(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_decoder_output_format_changed, inputFile.name, pcmSampleRate.toString(), pcmChannelCount.toString()))
                        }
                        MediaCodec.INFO_TRY_AGAIN_LATER -> { /* No hacer nada, reintentar */ }
                        else -> {
                            if (outputBufferId >= 0) {
                                if (bufferInfo.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM != 0) {
                                    sawOutputEOS = true
                                }
                                if (bufferInfo.size > 0) {
                                    val outputBuffer = codec.getOutputBuffer(outputBufferId)
                                    if (outputBuffer != null) {
                                        val pcmChunk = ByteArray(bufferInfo.size)
                                        outputBuffer.get(pcmChunk)
                                        outputBuffer.clear()
                                        fos.write(pcmChunk) // Escribir chunk PCM al archivo de salida
                                    }
                                }
                                codec.releaseOutputBuffer(outputBufferId, false) // Liberar buffer
                            }
                        }
                    }
                }
            }
            Log.i(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_completed, inputFile.name, outputFile.absolutePath))
            return@withContext PcmAudioData(outputFile, pcmSampleRate, pcmChannelCount)
        } catch (e: IOException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_ioexception, inputFile.name), e)
            outputFile.delete() // Eliminar archivo parcial si falla
            return@withContext null
        } catch (e: IllegalStateException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_illegalstate, inputFile.name), e)
            outputFile.delete()
            return@withContext null
        } catch (e: IllegalArgumentException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_illegalargument, inputFile.name), e)
            outputFile.delete()
            return@withContext null
        } catch (e: SecurityException) { // Podría ocurrir con MediaDrm o problemas de acceso
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_securityexception, inputFile.name), e)
            outputFile.delete()
            return@withContext null
        } catch (e: Exception) { // Captura genérica para errores inesperados
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_unexpected_error, inputFile.name), e)
            outputFile.delete()
            return@withContext null
        } finally {
            try { codec?.stop(); codec?.release() } catch (e: Exception) {Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_error_releasing_codec, inputFile.name), e)}
            try { extractor?.release() } catch (e: Exception) {Log.e(TAG_RECORD_AUDIO, getString(R.string.log_decode_m4a_to_pcm_error_releasing_extractor, inputFile.name), e)}
        }
    }

    // Objeto para utilidades de remuestreo y conversión de canales
    object Resampler {
        // Remuestrea audio PCM (solo mono a mono por ahora)
        fun resample(
            context: Context, // <--- AÑADIDO CONTEXTO
            pcmInputData: ByteArray,
            inputSampleRate: Int,
            inputChannelCount: Int,
            targetSampleRate: Int,
            targetChannelCount: Int
        ): ByteArray? {
            Log.d(TAG_RESAMPLER, context.getString(R.string.log_resampler_attempting_resample, inputSampleRate.toString(), inputChannelCount.toString(), targetSampleRate.toString(), targetChannelCount.toString()))
            if (inputChannelCount != 1 || targetChannelCount != 1) {
                Log.e(TAG_RESAMPLER, context.getString(R.string.log_resampler_mono_only, inputChannelCount.toString(), targetChannelCount.toString()))
                return null // Este resampleador simple solo soporta MONO a MONO
            }

            if (inputSampleRate == targetSampleRate) {
                Log.d(TAG_RESAMPLER, context.getString(R.string.log_resampler_rates_identical, inputSampleRate.toString()))
                return pcmInputData // No se necesita remuestreo
            }
            if (pcmInputData.isEmpty()) return ByteArray(0)

            // Convertir bytes a shorts (asumiendo PCM 16-bit Little Endian)
            val inputShorts = ShortArray(pcmInputData.size / 2)
            ByteBuffer.wrap(pcmInputData).order(ByteOrder.LITTLE_ENDIAN).asShortBuffer().get(inputShorts)

            if (inputShorts.isEmpty()) return ByteArray(0)

            // Calcular número de muestras de salida
            val numOutputSamples = (inputShorts.size.toDouble() * targetSampleRate.toDouble() / inputSampleRate.toDouble()).roundToInt()
            if (numOutputSamples == 0) return ByteArray(0)

            val outputShorts = ShortArray(numOutputSamples)
            val ratio = inputSampleRate.toDouble() / targetSampleRate.toDouble()

            // Interpolación lineal simple
            for (i in 0 until numOutputSamples) {
                val srcIndexFloat = i.toDouble() * ratio
                val srcIndex1 = floor(srcIndexFloat).toInt()
                var srcIndex2 = srcIndex1 + 1

                if (srcIndex1 >= inputShorts.size) { // Evitar IndexOutOfBounds
                    outputShorts[i] = inputShorts.lastOrNull() ?: 0 // Usar la última muestra o 0
                    continue
                }
                if (srcIndex2 >= inputShorts.size) { // Asegurar que srcIndex2 esté dentro de los límites
                    srcIndex2 = inputShorts.size - 1
                }

                val fraction = srcIndexFloat - srcIndex1
                val val1 = inputShorts[srcIndex1].toDouble()
                val val2 = inputShorts[srcIndex2].toDouble()
                outputShorts[i] = (val1 + fraction * (val2 - val1)).roundToInt().toShort()
            }

            // Convertir shorts de salida a bytes
            val outputByteBuffer = ByteBuffer.allocate(outputShorts.size * 2).order(ByteOrder.LITTLE_ENDIAN)
            outputByteBuffer.asShortBuffer().put(outputShorts)
            Log.d(TAG_RESAMPLER, context.getString(R.string.log_resampler_complete, inputShorts.size.toString(), numOutputSamples.toString()))
            return outputByteBuffer.array()
        }

        // Convierte PCM estéreo a mono promediando canales
        fun stereoToMono(context: Context, stereoPcmData: ByteArray): ByteArray? { // <--- AÑADIDO CONTEXTO
            if (stereoPcmData.size % 4 != 0) { // Cada muestra estéreo (L+R) son 4 bytes (2 por short)
                Log.e(TAG_RESAMPLER, context.getString(R.string.log_stereo_to_mono_invalid_size, stereoPcmData.size.toString()))
                return null
            }
            if (stereoPcmData.isEmpty()) return ByteArray(0)

            val numMonoSamples = stereoPcmData.size / 4 // Número de muestras mono resultantes
            val monoShorts = ShortArray(numMonoSamples)
            val stereoShortBuffer = ByteBuffer.wrap(stereoPcmData).order(ByteOrder.LITTLE_ENDIAN).asShortBuffer()

            for (i in 0 until numMonoSamples) {
                val left = stereoShortBuffer.get(i * 2).toInt()
                val right = stereoShortBuffer.get(i * 2 + 1).toInt()
                monoShorts[i] = ((left + right) / 2).toShort() // Promedio simple
            }

            val monoByteBuffer = ByteBuffer.allocate(monoShorts.size * 2).order(ByteOrder.LITTLE_ENDIAN)
            monoByteBuffer.asShortBuffer().put(monoShorts)
            Log.d(TAG_RESAMPLER, context.getString(R.string.log_stereo_to_mono_complete, numMonoSamples.toString()))
            return monoByteBuffer.array()
        }
    }


    // Ejecuta el pipeline de mejora de audio con IA (ONNX)
    private suspend fun runAiEnhancement(inputFile: File): File? = withContext(Dispatchers.IO) {
        if (!currentCoroutineContext().isActive) return@withContext null // Salir si la corrutina está cancelada
        val currentContext = context ?: return@withContext null // Necesario para cacheDir y Resampler
        Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_starting, inputFile.absolutePath))

        // Nombres de archivo para los pasos intermedios
        val decodedPcmFile = File(currentContext.cacheDir, DECODED_AUDIO_FOR_AI_FILENAME)
        val finalPcmForOnnxInput = File(currentContext.cacheDir, FINAL_PCM_FOR_ONNX_INPUT_FILENAME)
        val onnxProcessedPcmFile = File(currentContext.cacheDir, ONNX_PROCESSED_AUDIO_OUTPUT_FILENAME)
        val finalEnhancedM4aFile = File(currentContext.cacheDir, IA_PROCESSED_FILENAME_PREFIX + inputFile.nameWithoutExtension + getString(R.string.file_extension_m4a))


        // Variables para tensores ONNX, deben cerrarse en finally
        var featErbTensor: OnnxTensor? = null
        var featSpecTensor: OnnxTensor? = null
        var encResults: OrtResult? = null
        var dfDecResults: OrtResult? = null
        var erbDecResults: OrtResult? = null

        try {
            // 1. Decodificar M4A a PCM
            val pcmAudioData = decodeM4aToPcm(inputFile, decodedPcmFile)
            if (pcmAudioData == null || !currentCoroutineContext().isActive) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_failed_decode_or_cancelled, inputFile.name))
                return@withContext null
            }
            Log.i(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_pcm_decoded, inputFile.name, decodedPcmFile.absolutePath, pcmAudioData.sampleRate.toString(), pcmAudioData.channelCount.toString()))

            // 2. Leer bytes del PCM decodificado
            var pcmBytesToProcess: ByteArray? = FileInputStream(decodedPcmFile).use { it.readBytes() }
            if (pcmBytesToProcess == null || !currentCoroutineContext().isActive) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_error_reading_decoded_pcm, decodedPcmFile.name))
                return@withContext null
            }

            var currentSampleRate = pcmAudioData.sampleRate
            var currentChannelCount = pcmAudioData.channelCount

            // 3. Convertir a Mono si es necesario
            if (currentChannelCount > TARGET_CHANNEL_COUNT) {
                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_converting_to_mono, inputFile.name, currentChannelCount.toString()))
                pcmBytesToProcess = Resampler.stereoToMono(currentContext, pcmBytesToProcess) // <--- PASAR CONTEXTO
                if (pcmBytesToProcess == null || !currentCoroutineContext().isActive) { Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_failed_to_convert_to_mono, inputFile.name)); return@withContext null }
                currentChannelCount = TARGET_CHANNEL_COUNT
                Log.i(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_converted_to_mono, inputFile.name))
            }

            // 4. Remuestrear a TARGET_SAMPLE_RATE_HZ si es necesario
            if (currentSampleRate != TARGET_SAMPLE_RATE_HZ) {
                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_resampling, inputFile.name, currentSampleRate.toString(), TARGET_SAMPLE_RATE_HZ.toString()))
                pcmBytesToProcess = Resampler.resample(currentContext, pcmBytesToProcess, currentSampleRate, currentChannelCount, TARGET_SAMPLE_RATE_HZ, TARGET_CHANNEL_COUNT) // <--- PASAR CONTEXTO
                if (pcmBytesToProcess == null || !currentCoroutineContext().isActive) { Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_failed_to_resample, inputFile.name, TARGET_SAMPLE_RATE_HZ.toString())); return@withContext null }
                Log.i(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_resampled, inputFile.name, TARGET_SAMPLE_RATE_HZ.toString()))
            }

            if (pcmBytesToProcess == null || !currentCoroutineContext().isActive) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_pcm_data_null_after_conversion, inputFile.name))
                return@withContext null
            }
            FileOutputStream(finalPcmForOnnxInput).use { it.write(pcmBytesToProcess) } // Guardar PCM final para ONNX
            Log.i(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_final_pcm_ready_for_onnx, inputFile.name, TARGET_SAMPLE_RATE_HZ.toString(), TARGET_CHANNEL_COUNT.toString(), finalPcmForOnnxInput.absolutePath))

            // 5. Inferencia ONNX (si los modelos están cargados)
            if (encSession == null || dfDecSession == null || erbDecSession == null || ortEnvironment == null) {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_onnx_sessions_not_init, inputFile.name))
                // Si los modelos no están listos, usar el PCM preprocesado como salida (sin mejora IA)
                finalPcmForOnnxInput.copyTo(onnxProcessedPcmFile, overwrite = true)
            } else {
                // Calcular número de tramas (S) para los tensores de entrada
                val numSamples = pcmBytesToProcess.size / 2 // Asumiendo PCM 16-bit
                val numFramesS = (numSamples.toFloat() / DFN_STFT_HOP_SIZE.toFloat()).toInt()
                if (numFramesS <= 0) {
                    Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_num_frames_zero_or_negative, numFramesS.toString(), inputFile.name))
                    finalPcmForOnnxInput.copyTo(onnxProcessedPcmFile, overwrite = true) // Usar preprocesado
                } else {
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_num_pcm_samples_frames, inputFile.name, numSamples.toString(), numFramesS.toString()))

                    // Helper para obtener tensores de los resultados de ONNX
                    fun OrtResult.getTensorOrNull(name: String): OnnxTensor? {
                        val optionalValue: Optional<OnnxValue> = this.get(name)
                        if (!optionalValue.isPresent) {
                            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_output_not_found_in_onnx, name, this.toString(), inputFile.name))
                            return null
                        }
                        val value: OnnxValue = optionalValue.get()
                        return if (value is OnnxTensor) {
                            value
                        } else {
                            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_output_not_onnx_tensor, name, inputFile.name, value.type.toString()))
                            null
                        }
                    }

                    // Crear tensores de entrada para enc.onnx (rellenos con ceros por ahora)
                    // La implementación real necesitaría extraer características del audio PCM
                    val featErbShape = longArrayOf(1, 1, numFramesS.toLong(), 32L) // [B, C, S, F]
                    val featErbBuffer = FloatBuffer.allocate(featErbShape.reduce { acc, l -> acc * l }.toInt())
                    featErbTensor = OnnxTensor.createTensor(ortEnvironment, featErbBuffer, featErbShape)

                    val featSpecShape = longArrayOf(1, 2, numFramesS.toLong(), 96L) // [B, C, S, F]
                    val featSpecBuffer = FloatBuffer.allocate(featSpecShape.reduce { acc, l -> acc * l }.toInt())
                    featSpecTensor = OnnxTensor.createTensor(ortEnvironment, featSpecBuffer, featSpecShape)

                    val encInputs = mapOf("feat_erb" to featErbTensor!!, "feat_spec" to featSpecTensor!!)
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_running_enc_onnx, inputFile.name))
                    encResults = encSession!!.run(encInputs) // Ejecutar enc.onnx

                    // Obtener salidas de enc.onnx
                    val embTensor = encResults!!.getTensorOrNull("emb") ?: return@withContext null
                    val c0Tensor = encResults!!.getTensorOrNull("c0") ?: return@withContext null
                    val e0Tensor = encResults!!.getTensorOrNull("e0") ?: return@withContext null
                    val e1Tensor = encResults!!.getTensorOrNull("e1") ?: return@withContext null
                    val e2Tensor = encResults!!.getTensorOrNull("e2") ?: return@withContext null
                    val e3Tensor = encResults!!.getTensorOrNull("e3") ?: return@withContext null
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_enc_onnx_executed, inputFile.name, embTensor.info.shape.contentToString()))

                    // Ejecutar df_dec.onnx
                    val dfDecInputs = mapOf("emb" to embTensor, "c0" to c0Tensor)
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_running_df_dec_onnx, inputFile.name))
                    dfDecResults = dfDecSession!!.run(dfDecInputs)
                    val dfOutSignalTensor = dfDecResults!!.getTensorOrNull("302") ?: return@withContext null // Nombre de salida del modelo
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_df_dec_onnx_executed, inputFile.name, dfOutSignalTensor.info.shape.contentToString()))

                    // Ejecutar erb_dec.onnx
                    val erbDecInputs = mapOf("emb" to embTensor, "e3" to e3Tensor, "e2" to e2Tensor, "e1" to e1Tensor, "e0" to e0Tensor)
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_running_erb_dec_onnx, inputFile.name))
                    erbDecResults = erbDecSession!!.run(erbDecInputs)
                    val erbOutMaskTensor = erbDecResults!!.getTensorOrNull("m") ?: return@withContext null // Nombre de salida del modelo
                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_erb_dec_onnx_executed, inputFile.name, erbOutMaskTensor.info.shape.contentToString()))

                    // TODO: Implementar la lógica para usar las salidas de los modelos ONNX
                    // Por ahora, solo se simula copiando el PCM preprocesado
                    Log.w(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_simulating_ai_output, inputFile.name))
                    finalPcmForOnnxInput.copyTo(onnxProcessedPcmFile, overwrite = true)
                }
            }

            // 6. Re-codificar el PCM (procesado o no por IA) a M4A/AAC
            Log.d(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_starting_re_encoding, inputFile.name, onnxProcessedPcmFile.absolutePath))
            if (encodePcmToAacM4a(onnxProcessedPcmFile, finalEnhancedM4aFile)) {
                Log.i(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_re_encoding_complete, inputFile.name, finalEnhancedM4aFile.absolutePath))
                return@withContext finalEnhancedM4aFile
            } else {
                Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_failed_re_encoding, inputFile.name))
                finalEnhancedM4aFile.delete() // Eliminar archivo parcial si falla
                return@withContext null
            }

        } catch (e: OrtException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_ortexception, inputFile.name), e)
            return@withContext null
        } catch (e: IOException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_ioexception, inputFile.name), e)
            return@withContext null
        } catch (e: Exception) { // Captura de errores críticos
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_run_ai_enhancement_critical_unexpected_error, inputFile.name), e)
            return@withContext null
        } finally {
            // Liberar recursos ONNX
            featErbTensor?.close()
            featSpecTensor?.close()
            encResults?.close()
            dfDecResults?.close()
            erbDecResults?.close()

            // Eliminar archivos temporales PCM
            if (decodedPcmFile.exists()) decodedPcmFile.delete()
            if (finalPcmForOnnxInput.exists()) finalPcmForOnnxInput.delete()
            if (onnxProcessedPcmFile.exists()) onnxProcessedPcmFile.delete()
        }
    }


    // Codifica datos PCM crudos a un archivo M4A usando AAC
    @SuppressLint("NewApi") // Para MediaMuxer y MediaCodec
    private suspend fun encodePcmToAacM4a(pcmInputFile: File, m4aOutputFile: File): Boolean = withContext(Dispatchers.IO) {
        if (!currentCoroutineContext().isActive || !isAdded || context == null || !pcmInputFile.exists() || pcmInputFile.length() == 0L) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_preconditions_not_met, pcmInputFile.name, pcmInputFile.exists().toString(), pcmInputFile.length().toString()))
            return@withContext false
        }
        Log.d(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_starting, pcmInputFile.name, m4aOutputFile.name))

        val inputChannelCount = TARGET_CHANNEL_COUNT
        val inputSampleRate = TARGET_SAMPLE_RATE_HZ

        var encoder: MediaCodec? = null
        var muxer: MediaMuxer? = null
        val timeoutUs = 10000L // 10ms
        var trackIndex = -1
        var muxerStarted = false
        val bufferSize = 2048 * inputChannelCount * 2 // Tamaño de buffer razonable para PCM 16-bit

        try {
            // Configurar formato de salida AAC
            val outputFormat = AndroidMediaFormat.createAudioFormat(AAC_MIME_TYPE, inputSampleRate, inputChannelCount)
            outputFormat.setInteger(AndroidMediaFormat.KEY_AAC_PROFILE, MediaCodecInfo.CodecProfileLevel.AACObjectLC)
            outputFormat.setInteger(AndroidMediaFormat.KEY_BIT_RATE, AAC_BIT_RATE) // Bitrate deseado

            encoder = MediaCodec.createEncoderByType(AAC_MIME_TYPE)
            encoder.configure(outputFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE)
            encoder.start()

            muxer = MediaMuxer(m4aOutputFile.absolutePath, MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4)

            val bufferInfo = MediaCodec.BufferInfo()
            FileInputStream(pcmInputFile).use { fis ->
                val pcmChunkBuffer = ByteArray(bufferSize)
                var hasMoreInput = true
                var presentationTimeUsCumulative: Long = 0 // Acumulador para el tiempo de presentación
                var totalBytesRead: Long = 0

                // Bucle principal de codificación y multiplexación
                mainLoop@ while (true) {
                    if (!currentCoroutineContext().isActive) { Log.w(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_cancelled_coroutine, pcmInputFile.name)); return@withContext false }

                    // Alimentar datos PCM al codificador
                    if (hasMoreInput) {
                        val inputBufferId = encoder.dequeueInputBuffer(timeoutUs)
                        if (inputBufferId >= 0) {
                            val inputBuffer = encoder.getInputBuffer(inputBufferId)!!
                            inputBuffer.clear()
                            val bytesRead = fis.read(pcmChunkBuffer, 0, min(pcmChunkBuffer.size, inputBuffer.remaining()))
                            if (bytesRead > 0) {
                                inputBuffer.put(pcmChunkBuffer, 0, bytesRead)
                                totalBytesRead += bytesRead
                                // Calcular duración del chunk para el tiempo de presentación
                                val chunkDurationUs = (bytesRead.toDouble() / (inputChannelCount * 2.0 * inputSampleRate.toDouble()) * 1_000_000.0).toLong()
                                encoder.queueInputBuffer(inputBufferId, 0, bytesRead, presentationTimeUsCumulative, 0)
                                presentationTimeUsCumulative += chunkDurationUs
                            } else { // Fin del archivo PCM
                                encoder.queueInputBuffer(inputBufferId, 0, 0, presentationTimeUsCumulative, MediaCodec.BUFFER_FLAG_END_OF_STREAM)
                                hasMoreInput = false
                                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_eos_sent, pcmInputFile.name, totalBytesRead.toString()))
                            }
                        }
                    }

                    // Obtener datos codificados del codificador y escribirlos al multiplexor
                    var outputBufferId = encoder.dequeueOutputBuffer(bufferInfo, timeoutUs)
                    processingOutputLoop@ while (outputBufferId != MediaCodec.INFO_TRY_AGAIN_LATER) {
                        if (!currentCoroutineContext().isActive) { Log.w(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_cancelled_output_processing, pcmInputFile.name)); return@withContext false }
                        when (outputBufferId) {
                            MediaCodec.INFO_OUTPUT_FORMAT_CHANGED -> {
                                if (muxerStarted) {
                                    Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_format_changed_after_muxer, pcmInputFile.name))
                                    throw RuntimeException(getString(R.string.exception_format_changed_after_muxer_started))
                                }
                                val newFormat = encoder.outputFormat
                                trackIndex = muxer.addTrack(newFormat)
                                muxer.start()
                                muxerStarted = true
                                Log.i(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_muxer_started, pcmInputFile.name, newFormat.toString()))
                            }
                            MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED -> {
                                Log.d(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_output_buffers_changed, pcmInputFile.name))
                            }
                            else -> {
                                if (outputBufferId < 0) { // Error inesperado
                                    Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_dequeue_unexpected_code, outputBufferId.toString(), pcmInputFile.name))
                                    break@processingOutputLoop
                                }
                                if (!muxerStarted) { // Esperar a que el muxer inicie
                                    Log.w(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_output_before_format_changed, pcmInputFile.name))
                                    encoder.releaseOutputBuffer(outputBufferId, false) // Liberar y reintentar
                                    outputBufferId = encoder.dequeueOutputBuffer(bufferInfo, timeoutUs)
                                    continue@processingOutputLoop
                                }
                                val outputBuffer = encoder.getOutputBuffer(outputBufferId)!!
                                // Escribir datos al muxer si no es configuración del códec y hay datos
                                if (bufferInfo.flags and MediaCodec.BUFFER_FLAG_CODEC_CONFIG == 0 && bufferInfo.size != 0) {
                                    if (trackIndex != -1) {
                                        muxer.writeSampleData(trackIndex, outputBuffer, bufferInfo)
                                    } else {
                                        Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_muxer_track_index_invalid, pcmInputFile.name))
                                    }
                                }
                                encoder.releaseOutputBuffer(outputBufferId, false)
                                if (bufferInfo.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM != 0) {
                                    Log.d(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_eos_received_from_encoder, pcmInputFile.name))
                                    break@mainLoop // Salir del bucle principal
                                }
                            }
                        }
                        outputBufferId = encoder.dequeueOutputBuffer(bufferInfo, 0L) // Intentar obtener más salida sin esperar
                    }
                    // Si se recibió EOS, salir del bucle principal
                    if (bufferInfo.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM != 0) {
                        break@mainLoop
                    }
                    // Si no hay más entrada y el codificador necesita más tiempo, asumir que terminó o se atascó
                    if (!hasMoreInput && outputBufferId == MediaCodec.INFO_TRY_AGAIN_LATER){
                        Log.d(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_no_more_input_try_again, pcmInputFile.name))
                        break@mainLoop
                    }
                } // Fin del bucle principal
            }
            Log.i(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_loop_finished, pcmInputFile.name))
            return@withContext true
        } catch (e: IOException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_ioexception, pcmInputFile.name), e)
            m4aOutputFile.delete()
            return@withContext false
        } catch (e: IllegalStateException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_illegalstate, pcmInputFile.name), e)
            m4aOutputFile.delete()
            return@withContext false
        } catch (e: IllegalArgumentException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_illegalargument, pcmInputFile.name), e)
            m4aOutputFile.delete()
            return@withContext false
        } catch (e: MediaCodec.CodecException) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_codecexception, pcmInputFile.name), e)
            m4aOutputFile.delete()
            return@withContext false
        } catch (e: Exception) { // Captura genérica
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_unexpected_error, pcmInputFile.name), e)
            m4aOutputFile.delete()
            return@withContext false
        } finally {
            try { encoder?.stop(); encoder?.release() } catch (e: Exception) {Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_error_releasing_codec, pcmInputFile.name), e)}
            try { if (muxerStarted) muxer?.stop(); muxer?.release() } catch (e: Exception) { Log.e(TAG_RECORD_AUDIO, getString(R.string.log_encode_pcm_to_aac_error_releasing_muxer, pcmInputFile.name), e)}
        }
    }


    private fun releaseMediaRecorder() {
        try {
            mediaRecorder?.reset()
            mediaRecorder?.release()
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_release_mediarecorder_error), e)
        }
        mediaRecorder = null
    }

    private fun initializePlayer(uri: Uri) {
        if (!isAdded) return
        if (exoPlayer == null) {
            exoPlayer = ExoPlayer.Builder(requireContext()).build().apply {
                addListener(playerListener)
                val initialSpeed = playbackSpeeds[currentSpeedIndex]
                playbackParameters = PlaybackParameters(initialSpeed)
            }
        }
        val mediaItem = MediaItem.fromUri(uri)
        exoPlayer?.setMediaItem(mediaItem)
        exoPlayer?.seekTo(playerPlaybackPosition)
        exoPlayer?.playWhenReady = playerPlayWhenReady
        exoPlayer?.prepare()
        updatePlayerUI()
    }

    private fun releasePlayer() {
        if (::runnableUpdateSeekBar.isInitialized) {
            seekBarUpdateHandler.removeCallbacks(runnableUpdateSeekBar)
        }
        try {
            exoPlayer?.release()
        } catch (e: Exception) {
            Log.e(TAG_RECORD_AUDIO, getString(R.string.log_release_exoplayer_error), e)
        }
        exoPlayer = null
    }

    private fun deleteRecordedAudio(notifyListener: Boolean = true) {
        aiProcessingJob?.cancel(); aiProcessingJob = null // Cancelar procesamiento IA si está activo
        releasePlayer()
        audioFile?.delete(); audioFile = null
        processedAudioFile?.delete(); processedAudioFile = null
        currentPlayableAudioUri = null
        currentPlayableAudioOriginalName = null
        playerPlaybackPosition = 0
        playerPlayWhenReady = true
        currentSpeedIndex = 1 // Resetear velocidad a 1x
        recordingChronometer = 0L // Resetear cronómetro
        if(::waveformView.isInitialized) waveformView.clearWaveform() // Limpiar forma de onda
        currentRecordingState = RecordingState.IDLE // Volver a estado inicial
        updateUI()
        if (notifyListener) listener?.onAudioDeleted()
    }

    private fun cyclePlaybackSpeed() {
        currentSpeedIndex = (currentSpeedIndex + 1) % playbackSpeeds.size
        applyPlaybackSpeed()
        updatePlayerUI() // Actualizar texto del botón de velocidad en UI
    }

    private fun applyPlaybackSpeed() {
        exoPlayer?.let {
            val currentSpeedValue = playbackSpeeds[currentSpeedIndex]
            it.playbackParameters = PlaybackParameters(currentSpeedValue)
        }
    }

    private val playerListener = object : Player.Listener {
        override fun onIsPlayingChanged(isPlaying: Boolean) {
            updatePlayerUI()
            if (isPlaying && ::runnableUpdateSeekBar.isInitialized) {
                seekBarUpdateHandler.post(runnableUpdateSeekBar)
            } else if (::runnableUpdateSeekBar.isInitialized) {
                seekBarUpdateHandler.removeCallbacks(runnableUpdateSeekBar)
            }
        }

        override fun onPlaybackStateChanged(playbackState: Int) {
            updatePlayerUI()
            if (playbackState == Player.STATE_ENDED) {
                exoPlayer?.seekTo(0) // Volver al inicio
                exoPlayer?.playWhenReady = false // No reiniciar automáticamente
            }
        }

        override fun onPlayerError(error: PlaybackException) {
            if (!isAdded) return
            val errorMessage = getString(R.string.error_playback_failed_specific, error.localizedMessage ?: error.errorCodeName)
            Log.e(TAG_RECORD_AUDIO, "ExoPlayer error: ${error.errorCodeName} - ${error.localizedMessage}", error)
            showAlertDialog(getString(R.string.error_dialog_title), errorMessage)
            updatePlayerUI() // Actualizar UI para reflejar el error
        }
    }

    private fun initializeRecordingTimerRunnable() {
        recordingTimerRunnable = object : Runnable {
            override fun run() {
                if (currentRecordingState == RecordingState.RECORDING) {
                    recordingChronometer += 100 // Actualizar cada 100ms
                    val timeRemainingMs = MAX_RECORDING_DURATION_MS - recordingChronometer
                    binding.tvRecordingTimer.text = formatDuration(recordingChronometer, timeRemainingMs, currentRecordingState, true)

                    if (recordingChronometer >= MAX_RECORDING_DURATION_MS) {
                        // Detener grabación si se alcanza la duración máxima
                        if (currentRecordingState == RecordingState.RECORDING) { // Doble chequeo por si acaso
                            stopRecordingFlow(bySystem = false, message = getString(R.string.info_max_duration_reached, MAX_RECORDING_DURATION_MS / (60 * 1000)))
                        }
                    } else {
                        recordingTimerHandler.postDelayed(this, 100)
                    }
                }
            }
        }
    }

    private fun initializeAmplitudeUpdater() {
        amplitudeUpdater = object : Runnable {
            override fun run() {
                if (mediaRecorder != null && currentRecordingState == RecordingState.RECORDING && isAdded && ::waveformView.isInitialized) {
                    try {
                        waveformView.addAmplitude(mediaRecorder!!.maxAmplitude)
                        amplitudeUpdateHandler.postDelayed(this, AMPLITUDE_UPDATE_INTERVAL_MS)
                    } catch (e: IllegalStateException) {
                        Log.w(TAG_RECORD_AUDIO, getString(R.string.log_error_amplitude_updater_illegalstate), e)
                        amplitudeUpdateHandler.removeCallbacks(this) // Detener si hay error
                    }
                } else {
                    amplitudeUpdateHandler.removeCallbacks(this) // Detener si no se cumplen condiciones
                }
            }
        }
    }

    private fun formatDuration(elapsedMs: Long, remainingOrTotalMs: Long, state: RecordingState, includeMilliseconds: Boolean = false): String {
        val elapsedTotalSeconds = elapsedMs / 1000
        val elapsedMinutes = TimeUnit.SECONDS.toMinutes(elapsedTotalSeconds)
        val elapsedSeconds = elapsedTotalSeconds - TimeUnit.MINUTES.toSeconds(elapsedMinutes)
        val elapsedMillis = (elapsedMs % 1000) / 100 // Décimas de segundo

        return when (state) {
            RecordingState.RECORDING, RecordingState.PAUSED -> {
                val remValidMs = if (remainingOrTotalMs < 0) 0 else remainingOrTotalMs
                val remTotalSec = remValidMs / 1000
                val remMin = TimeUnit.SECONDS.toMinutes(remTotalSec)
                val remSec = remTotalSec - TimeUnit.MINUTES.toSeconds(remMin)
                val remMillis = (remValidMs % 1000) / 100
                if (includeMilliseconds) {
                    // Usar un formato de string que muestre ambas duraciones con milisegundos
                    getString(R.string.timer_format_recording_multiline_ms, elapsedMinutes, elapsedSeconds, elapsedMillis, remMin, remSec, remMillis)
                } else {
                    getString(R.string.timer_format_elapsed_remaining, elapsedMinutes, elapsedSeconds, remMin, remSec)
                }
            }
            RecordingState.STOPPED, RecordingState.AI_PROCESSING -> {
                // Mostrar solo duración total
                if (includeMilliseconds) {
                    getString(R.string.timer_format_total_duration_ms, elapsedMinutes, elapsedSeconds, elapsedMillis)
                } else {
                    getString(R.string.timer_format_total_duration, elapsedMinutes, elapsedSeconds)
                }
            }
            RecordingState.IDLE -> {
                // Mostrar duración máxima posible
                val totalDurSec = MAX_RECORDING_DURATION_MS / 1000
                val totalMin = TimeUnit.SECONDS.toMinutes(totalDurSec)
                val totalSec = totalDurSec - TimeUnit.MINUTES.toSeconds(totalMin)
                getString(R.string.timer_format_idle, totalMin, totalSec)
            }
        }
    }

    @SuppressLint("SetTextI18n")
    private fun updateUI() {
        if (_binding == null) return // Salir si el binding es nulo (vista destruida)

        val isRecordingOrPaused = currentRecordingState == RecordingState.RECORDING || currentRecordingState == RecordingState.PAUSED
        val isIdleOrStopped = currentRecordingState == RecordingState.IDLE || currentRecordingState == RecordingState.STOPPED
        val isAiProcessing = currentRecordingState == RecordingState.AI_PROCESSING

        // Habilitar/deshabilitar spinner de fuente de audio
        binding.spinnerAudioSource.isEnabled = isIdleOrStopped && currentPlayableAudioUri == null && !isAiProcessing

        // Habilitar/deshabilitar botones principales de grabación
        binding.btnStartStopRecording.isEnabled = !isAiProcessing // Siempre habilitado a menos que esté procesando IA
        binding.btnPauseResumeRecording.isEnabled = isRecordingOrPaused && Build.VERSION.SDK_INT >= Build.VERSION_CODES.N && !isAiProcessing

        // Configurar texto y visibilidad de elementos según el estado
        if (isAiProcessing) {
            binding.tvRecordingStatusDetailed.text = getString(R.string.info_ai_processing_audio)
            binding.btnStartStopRecording.text = getString(R.string.button_start_recording) // Botón principal muestra "Iniciar"
            binding.btnStartStopRecording.setIconResource(R.drawable.ic_record_red)
            binding.secondaryRecordingControls.visibility = View.GONE
            binding.recordedAudioPlayerSection.visibility = View.GONE
            binding.btnSaveLocalAudio?.visibility = View.GONE
            if(::waveformView.isInitialized) waveformView.visibility = View.VISIBLE // Mantener forma de onda visible
            binding.tvRecordingTimer.text = formatDuration(recordingChronometer, 0L, RecordingState.AI_PROCESSING, true)
        } else {
            when (currentRecordingState) {
                RecordingState.IDLE -> {
                    binding.tvRecordingStatusDetailed.text = getString(R.string.status_ready_to_record)
                    binding.btnStartStopRecording.text = getString(R.string.button_start_recording)
                    binding.btnStartStopRecording.setIconResource(R.drawable.ic_record_red)
                    binding.secondaryRecordingControls.visibility = View.GONE
                    binding.tvRecordingTimer.text = formatDuration(0, MAX_RECORDING_DURATION_MS, RecordingState.IDLE)
                    binding.btnSaveLocalAudio?.visibility = View.GONE
                    if(::waveformView.isInitialized) waveformView.visibility = View.VISIBLE // Mostrar forma de onda
                }
                RecordingState.RECORDING -> {
                    binding.tvRecordingStatusDetailed.text = getString(R.string.status_recording)
                    binding.btnStartStopRecording.text = getString(R.string.button_stop_recording)
                    binding.btnStartStopRecording.setIconResource(R.drawable.ic_stop_red)
                    binding.secondaryRecordingControls.visibility = View.VISIBLE
                    binding.btnPauseResumeRecording.text = getString(R.string.button_pause_recording)
                    binding.btnPauseResumeRecording.setIconResource(R.drawable.ic_pause_red)
                    binding.btnSaveLocalAudio?.visibility = View.GONE
                    if(::waveformView.isInitialized) waveformView.visibility = View.VISIBLE
                }
                RecordingState.PAUSED -> {
                    binding.tvRecordingStatusDetailed.text = getString(R.string.status_paused)
                    binding.btnStartStopRecording.text = getString(R.string.button_stop_recording)
                    binding.btnStartStopRecording.setIconResource(R.drawable.ic_stop_red)
                    binding.secondaryRecordingControls.visibility = View.VISIBLE
                    binding.btnPauseResumeRecording.text = getString(R.string.button_resume_recording)
                    binding.btnPauseResumeRecording.setIconResource(R.drawable.ic_play) // Icono de play para reanudar
                    // Mostrar tiempo transcurrido y restante
                    binding.tvRecordingTimer.text = formatDuration(recordingChronometer, MAX_RECORDING_DURATION_MS - recordingChronometer, RecordingState.PAUSED, true)
                    binding.btnSaveLocalAudio?.visibility = View.GONE
                    if(::waveformView.isInitialized) waveformView.visibility = View.VISIBLE
                }
                RecordingState.STOPPED -> {
                    binding.tvRecordingStatusDetailed.text = getString(R.string.status_finished)
                    // Mostrar duración total de la grabación
                    binding.tvRecordingTimer.text = formatDuration(if (currentPlayableAudioUri != null) recordingChronometer else 0L, 0L, RecordingState.STOPPED, true)
                    binding.btnStartStopRecording.text = getString(R.string.button_start_recording) // Listo para nueva grabación
                    binding.btnStartStopRecording.setIconResource(R.drawable.ic_record_red)
                    binding.secondaryRecordingControls.visibility = View.GONE
                    binding.btnSaveLocalAudio?.visibility = if (currentPlayableAudioUri != null) View.VISIBLE else View.GONE // Mostrar si hay audio
                    if(::waveformView.isInitialized) waveformView.visibility = View.VISIBLE // Mantener forma de onda
                }
                else -> { /* AI_PROCESSING ya cubierto */ }
            }
        }

        // Visibilidad del reproductor de audio grabado
        binding.recordedAudioPlayerSection.visibility = if (currentPlayableAudioUri != null && !isAiProcessing) View.VISIBLE else View.GONE
        if (currentPlayableAudioUri != null && !isAiProcessing) {
            binding.tvRecordedAudioFileName.text = getString(R.string.player_audio_file_name_format, currentPlayableAudioOriginalName ?: getString(R.string.default_audio_filename))
            updatePlayerUI() // Actualizar UI específica del reproductor
        } else if (!isAiProcessing) { // Si no hay audio y no se está procesando IA
            binding.seekBarRecordedAudio.visibility = View.GONE
            binding.tvPlayerTimer?.text = getString(R.string.player_timer_default_ss) // Formato MM:SS
            binding.btnSaveLocalAudio?.visibility = View.GONE
        }
    }

    private fun formatPlayerTimeSeconds(milliseconds: Long): String {
        if (milliseconds < 0) return "00:00" // Manejar valores negativos
        val totalSeconds = TimeUnit.MILLISECONDS.toSeconds(milliseconds.coerceAtLeast(0))
        val minutes = TimeUnit.SECONDS.toMinutes(totalSeconds)
        val seconds = totalSeconds - TimeUnit.MINUTES.toSeconds(minutes)
        return String.format(Locale.getDefault(), "%02d:%02d", minutes, seconds)
    }

    private fun updatePlayerTimerDisplay() {
        if (_binding == null || exoPlayer == null) { // Comprobar nulidad de binding también
            binding.tvPlayerTimer?.text = getString(R.string.player_timer_default_ss)
            return
        }
        val currentPos = exoPlayer?.currentPosition ?: 0
        val totalDur = exoPlayer?.duration ?: 0

        val currentFormatted = formatPlayerTimeSeconds(currentPos)
        val totalFormatted = formatPlayerTimeSeconds(if (totalDur > 0 && totalDur != com.google.android.exoplayer2.C.TIME_UNSET) totalDur else 0)

        binding.tvPlayerTimer?.text = "$currentFormatted / $totalFormatted"
    }

    private fun updatePlayerUI() {
        if (_binding == null || currentRecordingState == RecordingState.AI_PROCESSING) {
            // Si el binding es nulo o se está procesando IA, ocultar reproductor
            if (_binding != null) binding.recordedAudioPlayerSection.visibility = View.GONE
            return
        }

        // Determinar si el reproductor está realmente listo para reproducir
        val isPlayerActuallyReady = exoPlayer != null &&
                exoPlayer?.playbackState != Player.STATE_IDLE &&
                exoPlayer?.playbackState != Player.STATE_BUFFERING &&
                (exoPlayer?.duration ?: 0) > 0 &&
                exoPlayer?.duration != com.google.android.exoplayer2.C.TIME_UNSET

        val isPlaying = exoPlayer?.isPlaying ?: false

        // Visibilidad de botones Play/Pause
        binding.btnPlayRecordedAudio.visibility = if (isPlaying) View.GONE else View.VISIBLE
        binding.btnPauseRecordedAudio.visibility = if (isPlaying) View.VISIBLE else View.GONE

        // Habilitar/deshabilitar botones del reproductor
        binding.btnPlayRecordedAudio.isEnabled = isPlayerActuallyReady && !isPlaying
        binding.btnPauseRecordedAudio.isEnabled = isPlayerActuallyReady && isPlaying
        binding.btnDeleteRecordedAudio.isEnabled = currentPlayableAudioUri != null // Habilitar si hay audio
        binding.tvPlaybackSpeedRecorded.isEnabled = isPlayerActuallyReady
        binding.btnSaveLocalAudio?.isEnabled = currentPlayableAudioUri != null // Habilitar si hay audio

        // Actualizar SeekBar y temporizador del reproductor
        if (isPlayerActuallyReady) {
            binding.seekBarRecordedAudio.visibility = View.VISIBLE
            binding.tvPlayerTimer?.visibility = View.VISIBLE
            updatePlayerTimerDisplay()
            binding.seekBarRecordedAudio.max = (exoPlayer!!.duration).toInt()
            binding.seekBarRecordedAudio.progress = (exoPlayer!!.currentPosition).toInt()
        } else {
            binding.seekBarRecordedAudio.visibility = View.GONE
            binding.tvPlayerTimer?.text = getString(R.string.player_timer_default_ss)
            binding.tvPlayerTimer?.visibility = if (currentPlayableAudioUri != null) View.VISIBLE else View.GONE
            binding.seekBarRecordedAudio.progress = 0
            binding.seekBarRecordedAudio.max = 100 // Valor por defecto
        }

        // Actualizar texto del botón de velocidad
        if (::playbackSpeedStrings.isInitialized && playbackSpeedStrings.isNotEmpty()) {
            binding.tvPlaybackSpeedRecorded.text = playbackSpeedStrings.getOrElse(currentSpeedIndex) { playbackSpeedStrings[0] }
        } else {
            binding.tvPlaybackSpeedRecorded.text = "1x" // Fallback
        }
    }

    private fun initializeSeekBarUpdaterPlayer() {
        runnableUpdateSeekBar = object : Runnable {
            override fun run() {
                exoPlayer?.let { player ->
                    if (player.isPlaying && view != null && isAdded) { // Comprobar vista y fragmento
                        binding.seekBarRecordedAudio.progress = player.currentPosition.toInt()
                        updatePlayerTimerDisplay()
                        seekBarUpdateHandler.postDelayed(this, 200) // Actualizar cada 200ms
                    }
                }
            }
        }
    }

    private fun saveAudioToPublicMusicDirectory(sourceFileUri: Uri, desiredFileName: String) {
        if (!isAdded || context == null) {
            showSafeToast(getString(R.string.error_saving_audio_no_context))
            return
        }
        val resolver = requireContext().contentResolver
        var finalPathForDialog = "" // Para mostrar al usuario dónde se guardó

        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.Q) {
            // Para Android Q y superior, usar MediaStore
            val audioCollection = MediaStore.Audio.Media.getContentUri(MediaStore.VOLUME_EXTERNAL_PRIMARY)
            val relativePath = Environment.DIRECTORY_MUSIC + File.separator + getString(R.string.app_recordings_folder_name)
            finalPathForDialog = "Música/${getString(R.string.app_recordings_folder_name)}/$desiredFileName"

            val newAudioDetails = ContentValues().apply {
                put(MediaStore.Audio.Media.DISPLAY_NAME, desiredFileName)
                put(MediaStore.Audio.Media.MIME_TYPE, "audio/m4a") // Asumir M4A
                put(MediaStore.Audio.Media.RELATIVE_PATH, relativePath)
                put(MediaStore.Audio.Media.IS_PENDING, 1) // Marcar como pendiente hasta que se escriba
            }
            var newAudioUri: Uri? = null
            try {
                newAudioUri = resolver.insert(audioCollection, newAudioDetails)
                if (newAudioUri == null) {
                    showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_saving_audio_failed_mediastore))
                    return
                }
                resolver.openOutputStream(newAudioUri).use { output ->
                    resolver.openInputStream(sourceFileUri).use { input ->
                        if (input == null || output == null) throw IOException(getString(R.string.error_saving_audio_copy_failed_streams_null))
                        input.copyTo(output)
                    }
                }
                newAudioDetails.clear()
                newAudioDetails.put(MediaStore.Audio.Media.IS_PENDING, 0) // Marcar como no pendiente
                resolver.update(newAudioUri, newAudioDetails, null, null)
                showAlertDialog(getString(R.string.info_audio_saved_locally), getString(R.string.success_audio_saved_to_music_path_dialog, finalPathForDialog))
            } catch (ioe: IOException) {
                Log.e(TAG_RECORD_AUDIO, "IOException al guardar audio (API Q+).", ioe)
                showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_saving_audio_copy_failed, ioe.localizedMessage ?: getString(R.string.unknown_error)))
                newAudioUri?.let { resolver.delete(it, null, null) } // Eliminar entrada si falla la copia
            } catch (e: Exception) { // Captura genérica
                Log.e(TAG_RECORD_AUDIO, "Excepción al guardar audio (API Q+).", e)
                showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_saving_audio_copy_failed, e.localizedMessage ?: getString(R.string.unknown_error)))
                newAudioUri?.let { resolver.delete(it, null, null) }
            }
        } else {
            // Para versiones anteriores a Android Q, solicitar permiso de escritura si es necesario
            if (ContextCompat.checkSelfPermission(requireContext(), Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) {
                requestWriteStoragePermissionLauncher.launch(Manifest.permission.WRITE_EXTERNAL_STORAGE)
                return
            }
            val publicMusicDir = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_MUSIC)
            val appDir = File(publicMusicDir, getString(R.string.app_recordings_folder_name))
            if (!appDir.exists() && !appDir.mkdirs()) {
                showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_creating_directory_failed, appDir.name))
                return
            }
            val outputFile = File(appDir, desiredFileName)
            finalPathForDialog = outputFile.absolutePath
            try {
                FileOutputStream(outputFile).use { output ->
                    resolver.openInputStream(sourceFileUri)?.use { input ->
                        input.copyTo(output)
                    } ?: throw IOException(getString(R.string.error_saving_audio_copy_failed_input_null))
                }
                showAlertDialog(getString(R.string.info_audio_saved_locally), getString(R.string.success_audio_saved_to_music_path_dialog, finalPathForDialog))
                // Notificar a MediaScanner para que el archivo aparezca en otras apps
                MediaScannerConnection.scanFile(requireContext(), arrayOf(outputFile.toString()), null, null)
            } catch (ioe: IOException) {
                Log.e(TAG_RECORD_AUDIO, "IOException al guardar audio (API < Q).", ioe)
                showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_saving_audio_copy_failed, ioe.localizedMessage ?: getString(R.string.unknown_error)))
            } catch (e: Exception) { // Captura genérica
                Log.e(TAG_RECORD_AUDIO, "Excepción al guardar audio (API < Q).", e)
                showAlertDialog(getString(R.string.error_dialog_title), getString(R.string.error_saving_audio_copy_failed, e.localizedMessage ?: getString(R.string.unknown_error)))
            }
        }
    }


    // --- Funciones públicas para la actividad contenedora ---
    fun getRecordedAudioUri(): Uri? = currentPlayableAudioUri
    fun getRecordedAudioOriginalName(): String? = currentPlayableAudioOriginalName
    val isRecording: Boolean get() = currentRecordingState == RecordingState.RECORDING || currentRecordingState == RecordingState.PAUSED

    fun resetState() {
        aiProcessingJob?.cancel(); aiProcessingJob = null
        if (isRecording) { // Si está grabando o pausado
            amplitudeUpdateHandler.removeCallbacks(amplitudeUpdater)
            stopRecordingFlow(bySystem = true) // Detener la grabación (marcar como por sistema para no notificar)
        }
        deleteRecordedAudio(notifyListener = false) // Eliminar cualquier audio y resetear UI, sin notificar
        currentRecordingState = RecordingState.IDLE // Asegurar estado IDLE
        recordingChronometer = 0L
        if(::waveformView.isInitialized) waveformView.clearWaveform()
        listener?.onRecordingStateChanged(isRecording = false) // Notificar que ya no se está grabando
        updateUI() // Actualizar UI final
    }

    companion object {
        private const val TAG_RECORD_AUDIO = "RecordAudioFragment" // Etiqueta específica para logs
        private const val TAG_RESAMPLER = "ResamplerUtil" // Etiqueta para logs de Resampler
        @JvmStatic
        fun newInstance() = RecordAudioFragment()
    }
}
