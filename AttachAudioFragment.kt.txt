package com.example.mexicoparanormal

import android.content.Context
import android.media.MediaCodec
import android.media.MediaExtractor
import android.media.MediaFormat
import android.media.MediaMetadataRetriever
import android.net.Uri
import android.os.Build
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.os.ParcelFileDescriptor
import android.provider.OpenableColumns
import android.util.Log
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.SeekBar
import android.widget.Toast
import androidx.activity.result.contract.ActivityResultContracts
import androidx.appcompat.app.AlertDialog
import androidx.fragment.app.Fragment
import androidx.lifecycle.lifecycleScope // La necesitas para el viewLifecycleOwner.lifecycleScope
// import androidx.lifecycle.viewLifecycleOwner // MODIFICACIÓN: Elimina esta línea, ya no es necesaria aquí.
import com.example.mexicoparanormal.databinding.FragmentAttachAudioBinding
import com.google.android.exoplayer2.ExoPlayer
import com.google.android.exoplayer2.MediaItem
import com.google.android.exoplayer2.PlaybackException
import com.google.android.exoplayer2.PlaybackParameters
import com.google.android.exoplayer2.Player
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.isActive
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import java.io.FileNotFoundException
import java.io.IOException
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.ShortBuffer
import java.util.Locale
import java.util.concurrent.TimeUnit
import kotlin.math.abs
import kotlin.math.max
import kotlinx.coroutines.currentCoroutineContext

class AttachAudioFragment : Fragment(), WaveformView.OnWaveformInteractionListener {

    private var _binding: FragmentAttachAudioBinding? = null
    private val binding get() = _binding!!

    private var exoPlayer: ExoPlayer? = null
    private var attachedAudioUri: Uri? = null
    private var attachedAudioOriginalName: String? = null

    private val playbackSpeeds = floatArrayOf(0.5f, 1.0f, 1.5f, 2.0f)
    private lateinit var playbackSpeedStrings: Array<String>
    private var currentSpeedIndex = 1 // Índice para 1.0x

    private var playbackPosition: Long = 0
    private var playWhenReady: Boolean = true

    private val seekBarUpdateHandler = Handler(Looper.getMainLooper())
    private lateinit var runnableUpdateSeekBar: Runnable

    private var currentToast: Toast? = null
    private lateinit var waveformView: WaveformView
    private var waveformGenerationJob: Job? = null


    interface AudioAttachListener {
        fun onAudioAttached(uri: Uri?, originalFileName: String?)
        fun onAttachedAudioDeleted()
    }
    private var listener: AudioAttachListener? = null

    companion object {
        private const val TAG = "AttachAudioFragment"
        private const val MAX_AUDIO_SIZE_MB = 20
        private const val MAX_AUDIO_DURATION_MINUTES = 20
        private const val WAVEFORM_SAMPLES = WaveformView.WAVEFORM_SAMPLES_CONST
        @JvmStatic
        fun newInstance() = AttachAudioFragment()
    }

    private val selectAudioLauncher =
        registerForActivityResult(ActivityResultContracts.GetContent()) { uri: Uri? ->
            if (uri != null) {
                try {
                    val fileName = getFileNameFromUri(uri)
                    val fileSize = getFileSizeFromUri(uri)
                    val type = requireContext().contentResolver.getType(uri)

                    val allowedMimeTypes = listOf(
                        "audio/mpeg", "audio/opus", "audio/ogg",
                        "audio/mp4", "audio/x-m4a", "audio/aac"
                    )

                    var isValidType = false
                    if (type != null && allowedMimeTypes.contains(type.lowercase(Locale.getDefault()))) {
                        isValidType = true
                    } else {
                        val fileExtension = fileName.substringAfterLast('.', "").lowercase(Locale.getDefault())
                        if (listOf("mp3", "opus", "ogg", "m4a", "aac").contains(fileExtension)) {
                            isValidType = true
                        }
                    }

                    if (!isValidType) {
                        showSafeToast(getString(R.string.error_audio_invalid_type_detailed, fileName, type ?: getString(R.string.unknown_format)))
                        return@registerForActivityResult
                    }

                    val maxFileSizeBytes = MAX_AUDIO_SIZE_MB * 1024 * 1024
                    if (fileSize > maxFileSizeBytes) {
                        showSafeToast(getString(R.string.error_audio_file_too_large_detailed, MAX_AUDIO_SIZE_MB, fileSize / (1024 * 1024)))
                        return@registerForActivityResult
                    }

                    val durationMs = getAudioDuration(uri)
                    if (durationMs == null) {
                        showSafeToast(getString(R.string.error_audio_cannot_get_duration, fileName))
                        return@registerForActivityResult
                    }
                    if (durationMs > MAX_AUDIO_DURATION_MINUTES * 60 * 1000) {
                        showSafeToast(getString(R.string.error_audio_duration_exceeded_detailed, MAX_AUDIO_DURATION_MINUTES, durationMs / (60 * 1000)))
                        return@registerForActivityResult
                    }

                    releasePlayer()
                    waveformGenerationJob?.cancel()
                    attachedAudioUri = uri
                    attachedAudioOriginalName = fileName
                    showAttachedAudioPlayer(uri, fileName)
                    listener?.onAudioAttached(attachedAudioUri, attachedAudioOriginalName)
                    showSafeToast(getString(R.string.audio_selection_successful))

                } catch (e: SecurityException) {
                    Log.e(TAG, getString(R.string.log_error_security_exception_select_audio, e.message), e)
                    showSafeToast(getString(R.string.error_accessing_file_permission, uri.lastPathSegment ?: getString(R.string.selected_audio_default_name)))
                } catch (e: Exception) {
                    Log.e(TAG, getString(R.string.log_error_processing_selected_audio, e.message), e)
                    showSafeToast(getString(R.string.upload_file_error_message, e.localizedMessage ?: getString(R.string.unknown_error)))
                }
            } else {
                showSafeToast(getString(R.string.error_audio_selection_cancelled))
            }
        }

    override fun onAttach(context: Context) {
        super.onAttach(context)
        if (context is AudioAttachListener) {
            listener = context
        } else {
            throw ClassCastException(getString(R.string.error_must_implement_audio_attach_listener, context.toString()))
        }
    }

    override fun onCreateView(
        inflater: LayoutInflater, container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View {
        _binding = FragmentAttachAudioBinding.inflate(inflater, container, false)
        waveformView = binding.waveformViewAttach
        waveformView.onWaveformInteractionListener = this
        return binding.root
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)
        binding.tvInfoAttachFile.text = getString(R.string.info_attach_audio_file, MAX_AUDIO_SIZE_MB, MAX_AUDIO_DURATION_MINUTES)
        playbackSpeedStrings = arrayOf("0.5x", getString(R.string.text_playback_speed_1x), "1.5x", "2x")
        setupUI()
        initializeSeekBarUpdater()

        if (attachedAudioUri != null && attachedAudioOriginalName != null) {
            showAttachedAudioPlayer(attachedAudioUri!!, attachedAudioOriginalName!!)
        }
    }

    private fun setupUI() {
        binding.btnSelectAudioFile.visibility = View.VISIBLE
        binding.waveformContainer.visibility = View.GONE
        binding.tvLoadingWaveformIndicator.visibility = View.GONE
        binding.attachedAudioPlayerSection.visibility = View.GONE
        binding.seekBarAttachedAudio.visibility = View.GONE
        binding.tvPlayerTimerAttach?.text = getString(R.string.player_timer_default_ss)
        if(::waveformView.isInitialized) waveformView.clearWaveform()


        binding.btnSelectAudioFile.setOnClickListener {
            if (exoPlayer?.isPlaying == true) pausePlayback()
            selectAudioLauncher.launch("audio/*")
        }
        binding.btnPlayAttachedAudio.setOnClickListener {
            attachedAudioUri?.let { uri ->
                if (exoPlayer?.isPlaying != true) {
                    if (exoPlayer == null || exoPlayer?.currentMediaItem?.mediaId != uri.toString() || exoPlayer?.playbackState == Player.STATE_ENDED) {
                        initializeAndPlayAttachedAudio(uri, true)
                    } else {
                        exoPlayer?.play()
                    }
                }
            } ?: showSafeToast(getString(R.string.error_no_audio_to_play))
        }
        binding.btnPauseAttachedAudio.setOnClickListener { pausePlayback() }
        binding.btnDeleteAttachedAudio.setOnClickListener { deleteAttachedAudio() }
        binding.tvPlaybackSpeedAttached.setOnClickListener { cyclePlaybackSpeed(); applyPlaybackSpeed() }
        binding.seekBarAttachedAudio.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener {
            override fun onProgressChanged(seekBar: SeekBar?, progress: Int, fromUser: Boolean) {
                if (fromUser && exoPlayer != null) {
                    val newPosition = progress.toLong()
                    exoPlayer?.seekTo(newPosition)
                    if (::waveformView.isInitialized && (exoPlayer?.duration ?: 0L) > 0L) {
                        waveformView.updatePlaybackIndicator(newPosition, exoPlayer!!.duration)
                    }
                }
            }
            override fun onStartTrackingTouch(seekBar: SeekBar?) { /* No se necesita implementación */ }
            override fun onStopTrackingTouch(seekBar: SeekBar?) { /* No se necesita implementación */ }
        })
        binding.tvPlaybackSpeedAttached.text = playbackSpeedStrings[currentSpeedIndex]
    }

    private fun showAttachedAudioPlayer(uri: Uri, fileName: String) {
        binding.btnSelectAudioFile.visibility = View.GONE

        if(::waveformView.isInitialized) waveformView.clearWaveform()

        launchAudioAnalysis(uri)

        binding.tvAttachedAudioInfo.text = fileName
        binding.attachedAudioPlayerSection.visibility = View.VISIBLE
        initializeExoPlayer(uri, false)
    }

    private fun launchAudioAnalysis(audioUri: Uri) {
        if (!isAdded || !::waveformView.isInitialized) {
            Log.w(TAG, "launchAudioAnalysis: Fragment not added or waveformView not initialized. URI: $audioUri")
            return
        }
        Log.d(TAG, getString(R.string.log_launch_audio_analysis, audioUri.toString()))

        binding.waveformContainer.visibility = View.VISIBLE
        binding.waveformViewAttach.visibility = View.GONE
        binding.tvLoadingWaveformIndicator.visibility = View.VISIBLE

        waveformGenerationJob?.cancel()
        // Corrección: Usar viewLifecycleOwner.lifecycleScope
        waveformGenerationJob = viewLifecycleOwner.lifecycleScope.launch(Dispatchers.IO) {
            val normalizedAmplitudes = extractAmplitudes(requireContext(), audioUri, WAVEFORM_SAMPLES)

            if (!isActive) { // isActive se refiere a viewLifecycleOwner.lifecycleScope.isActive
                Log.d(TAG, getString(R.string.log_waveform_job_cancelled, audioUri.toString()))
                withContext(Dispatchers.Main) {
                    if (isAdded && _binding != null) { // Comprobar _binding
                        binding.tvLoadingWaveformIndicator.visibility = View.GONE
                    }
                }
                return@launch
            }

            withContext(Dispatchers.Main) {
                if (!isAdded || _binding == null ) { // Comprobación principal aquí
                    Log.w(TAG, "AttachAudioFragment: Fragment not added or binding is null after extraction. URI: $audioUri")
                    return@withContext
                }
                binding.tvLoadingWaveformIndicator.visibility = View.GONE

                if (normalizedAmplitudes.isNotEmpty()) {
                    Log.i(TAG, "AttachAudioFragment: Attempting to display waveform. Data available. URI: $audioUri. Amplitudes count: ${normalizedAmplitudes.size}")
                    binding.waveformContainer.visibility = View.VISIBLE
                    binding.waveformViewAttach.visibility = View.VISIBLE
                    binding.waveformViewAttach.post {
                        // Corrección: Condición actualizada dentro del post
                        if (isAdded && _binding != null) {
                            Log.d(TAG, "AttachAudioFragment: Inside post, setting waveform data. URI: $audioUri")
                            waveformView.setWaveformData(normalizedAmplitudes)
                            Log.d(TAG, getString(R.string.log_waveform_data_set) + " for URI: $audioUri")
                        } else {
                            val reason = mutableListOf<String>()
                            if (!isAdded) reason.add("fragment not added")
                            if (_binding == null) reason.add("binding is null")
                            Log.w(TAG, "AttachAudioFragment: Inside post, NOT setting waveform data (${reason.joinToString()}). URI: $audioUri")
                        }
                    }
                    Log.d(TAG, getString(R.string.log_waveform_update_samples, normalizedAmplitudes.size))
                } else {
                    Log.w(TAG, "AttachAudioFragment: No normalized amplitudes to display. URI: $audioUri")
                    if(::waveformView.isInitialized) waveformView.clearWaveform()
                    binding.waveformViewAttach.visibility = View.GONE
                    binding.waveformContainer.visibility = View.GONE
                    showSafeToast(getString(R.string.error_generating_waveform_preview))
                }
            }
        }
    }

    private suspend fun extractAmplitudes(context: Context, audioUri: Uri, targetSamples: Int): List<Float> {
        Log.d(TAG, getString(R.string.log_starting_amplitude_extraction, audioUri.toString(), targetSamples.toString()))
        val rawAmplitudes = mutableListOf<Int>()
        var extractor: MediaExtractor? = null
        var codec: MediaCodec? = null
        val contentResolver = context.contentResolver
        var pfd: ParcelFileDescriptor? = null

        try {
            extractor = MediaExtractor()
            pfd = contentResolver.openFileDescriptor(audioUri, "r")
            if (pfd == null) {
                Log.e(TAG, getString(R.string.log_error_open_filedescriptor_null, audioUri.toString()))
                return emptyList()
            }
            extractor.setDataSource(pfd.fileDescriptor)
            Log.d(TAG, getString(R.string.log_mediasource_set_successful))


            var audioTrackIndex = -1
            var inputFormat: MediaFormat? = null
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME)
                Log.d(TAG, getString(R.string.log_track_info, i.toString(), mime.toString(), format.toString()))
                if (mime?.startsWith("audio/") == true) {
                    audioTrackIndex = i
                    inputFormat = format
                    Log.d(TAG, getString(R.string.log_audio_track_found, i.toString(), inputFormat.toString()))
                    break
                }
            }

            if (audioTrackIndex == -1 || inputFormat == null) {
                Log.e(TAG, getString(R.string.log_no_audio_track_found_uri, audioUri.toString()))
                return emptyList()
            }

            extractor.selectTrack(audioTrackIndex)
            val mimeType = inputFormat.getString(MediaFormat.KEY_MIME) ?: run {
                Log.e(TAG, getString(R.string.log_mime_type_null_for_audio_track))
                return emptyList()
            }
            Log.d(TAG, getString(R.string.log_selected_audio_track_mime, audioTrackIndex.toString(), mimeType))

            codec = MediaCodec.createDecoderByType(mimeType)
            Log.d(TAG, getString(R.string.log_mediacodec_decoder_created, mimeType))
            codec.configure(inputFormat, null, null, 0)
            codec.start()
            Log.d(TAG, getString(R.string.log_mediacodec_configured_started))

            val bufferInfo = MediaCodec.BufferInfo()
            var endOfInput = false
            var endOfOutput = false

            val audioDurationUsFromFormat = if (inputFormat.containsKey(MediaFormat.KEY_DURATION)) {
                inputFormat.getLong(MediaFormat.KEY_DURATION)
            } else { 0L }
            Log.d(TAG, getString(R.string.log_duration_from_mediaformat_us, audioDurationUsFromFormat.toString()))

            val audioDurationMs = getAudioDuration(audioUri) ?: 0L
            val finalAudioDurationUs = if (audioDurationUsFromFormat > 0) audioDurationUsFromFormat else audioDurationMs * 1000
            Log.d(TAG, getString(R.string.log_final_effective_duration_us, finalAudioDurationUs.toString()))

            val sampleRate = if (inputFormat.containsKey(MediaFormat.KEY_SAMPLE_RATE)) {
                inputFormat.getInteger(MediaFormat.KEY_SAMPLE_RATE)
            } else {
                Log.w(TAG, getString(R.string.log_samplerate_not_in_format_defaulting))
                44100
            }
            Log.d(TAG, getString(R.string.log_samplerate_info, sampleRate.toString()))

            val totalExpectedSamplesInFile = if (finalAudioDurationUs > 0 && sampleRate > 0) (finalAudioDurationUs * sampleRate / 1_000_000L) else 0L
            Log.d(TAG, getString(R.string.log_total_expected_samples_in_file, totalExpectedSamplesInFile.toString()))

            val pcmSamplesPerWaveformPoint = if (totalExpectedSamplesInFile > 0 && targetSamples > 0) {
                (totalExpectedSamplesInFile / targetSamples).coerceAtLeast(1L)
            } else {
                (sampleRate * 0.02).toLong().coerceAtLeast(1L)
            }
            Log.d(TAG, getString(R.string.log_pcm_samples_per_waveform_point, pcmSamplesPerWaveformPoint.toString()))

            var currentPcmSamplesInChunk: Long = 0
            var peakAmplitudeInChunk = 0
            val timeoutUs: Long = 10000
            var totalPcmSamplesProcessed: Long = 0
            var inputBufferDequeuedCount = 0
            var outputBufferDequeuedCount = 0
            var iterations = 0

            val maxIterationsSafetyFactor = if (totalExpectedSamplesInFile > 0) 2 else 500
            val maxIterations = (totalExpectedSamplesInFile / pcmSamplesPerWaveformPoint.coerceAtLeast(1) * maxIterationsSafetyFactor)
                .coerceAtLeast((targetSamples * 400L))
            Log.d(TAG, getString(R.string.log_max_iterations_safety_break, maxIterations.toString()))


            mainLoop@ while (!endOfOutput && rawAmplitudes.size < targetSamples && iterations < maxIterations && currentCoroutineContext().isActive) {
                iterations++

                if (iterations % 5000 == 0) Log.d(TAG, getString(R.string.log_main_loop_iteration_status, iterations.toString(), rawAmplitudes.size.toString(), endOfInput.toString(), endOfOutput.toString()))

                if (!endOfInput) {
                    try {
                        val inputBufferId = codec.dequeueInputBuffer(timeoutUs)
                        if (inputBufferId >= 0) {
                            inputBufferDequeuedCount++
                            val inputBuffer = codec.getInputBuffer(inputBufferId)
                            if (inputBuffer != null) {
                                val sampleSize = extractor.readSampleData(inputBuffer, 0)
                                if (sampleSize < 0) {
                                    codec.queueInputBuffer(inputBufferId, 0, 0, 0L, MediaCodec.BUFFER_FLAG_END_OF_STREAM)
                                    endOfInput = true
                                    Log.d(TAG, getString(R.string.log_eos_sent_to_decoder, inputBufferDequeuedCount.toString()))
                                } else if (sampleSize > 0) {
                                    codec.queueInputBuffer(inputBufferId, 0, sampleSize, extractor.sampleTime, 0)
                                    extractor.advance()
                                } else {
                                    codec.queueInputBuffer(inputBufferId, 0, 0, extractor.sampleTime, 0)
                                }
                            } else { Log.w(TAG, getString(R.string.log_getinputbuffer_returned_null, inputBufferId.toString()))}
                        }
                    } catch (e: MediaCodec.CodecException) {
                        Log.e(TAG, getString(R.string.log_codecexception_input_processing, e.message.toString(), e.isTransient.toString(), e.isRecoverable.toString()), e)
                        if (!e.isRecoverable) break@mainLoop
                    } catch (e: IllegalStateException) {
                        Log.e(TAG, getString(R.string.log_illegalstateexception_input_processing, e.message.toString()), e)
                        break@mainLoop
                    } catch (e: Exception) {
                        Log.e(TAG, getString(R.string.log_unexpected_exception_input_processing, e.message.toString()), e)
                        break@mainLoop
                    }
                }

                var outputBufferId: Int
                try {
                    outputBufferId = codec.dequeueOutputBuffer(bufferInfo, timeoutUs)
                } catch (e: MediaCodec.CodecException) {
                    Log.e(TAG, getString(R.string.log_codecexception_dequeueoutputbuffer, e.message.toString(), e.isTransient.toString(), e.isRecoverable.toString()), e)
                    if (!e.isRecoverable) break@mainLoop
                    continue@mainLoop
                } catch (e: IllegalStateException) {
                    Log.e(TAG, getString(R.string.log_illegalstateexception_dequeueoutputbuffer, e.message.toString()), e)
                    break@mainLoop
                } catch (e: Exception) {
                    Log.e(TAG, getString(R.string.log_unexpected_exception_dequeueoutputbuffer, e.message.toString()), e)
                    break@mainLoop
                }


                when (outputBufferId) {
                    MediaCodec.INFO_OUTPUT_FORMAT_CHANGED -> {
                        val newFormat = codec.outputFormat
                        Log.i(TAG, getString(R.string.log_decoder_output_format_changed, newFormat.toString()))
                    }
                    MediaCodec.INFO_TRY_AGAIN_LATER -> { /* Log.v(TAG, "dequeueOutputBuffer timed out"); */ }
                    MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED -> { Log.d(TAG, getString(R.string.log_output_buffers_changed_deprecated)) }
                    else -> {
                        if (outputBufferId >= 0) {
                            outputBufferDequeuedCount++
                            if (bufferInfo.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM != 0) {
                                Log.d(TAG, getString(R.string.log_eos_flag_received_output, outputBufferDequeuedCount.toString()))
                                endOfOutput = true
                            }
                            if (bufferInfo.size > 0) {
                                val outputBuffer = codec.getOutputBuffer(outputBufferId)
                                if (outputBuffer != null) {
                                    outputBuffer.order(ByteOrder.nativeOrder())
                                    val shortBuffer = outputBuffer.asShortBuffer()

                                    while (shortBuffer.hasRemaining() && rawAmplitudes.size < targetSamples) {
                                        val sample = shortBuffer.get().toInt()
                                        peakAmplitudeInChunk = max(peakAmplitudeInChunk, abs(sample))
                                        currentPcmSamplesInChunk++
                                        totalPcmSamplesProcessed++

                                        if (currentPcmSamplesInChunk >= pcmSamplesPerWaveformPoint) {
                                            rawAmplitudes.add(peakAmplitudeInChunk)
                                            peakAmplitudeInChunk = 0
                                            currentPcmSamplesInChunk = 0
                                            if (rawAmplitudes.size >= targetSamples) {
                                                Log.d(TAG, getString(R.string.log_target_samples_waveform_reached, targetSamples.toString()))
                                                break@mainLoop
                                            }
                                        }
                                    }
                                    outputBuffer.clear()
                                } else { Log.w(TAG, getString(R.string.log_getoutputbuffer_returned_null, outputBufferId.toString())) }
                            }
                            codec.releaseOutputBuffer(outputBufferId, false)
                        } else {
                            Log.w(TAG, getString(R.string.log_dequeueoutputbuffer_unexpected_index, outputBufferId.toString()))
                        }
                    }
                }
            }

            if (peakAmplitudeInChunk > 0 && rawAmplitudes.size < targetSamples) {
                rawAmplitudes.add(peakAmplitudeInChunk)
                Log.d(TAG, getString(R.string.log_added_final_peak_amplitude, peakAmplitudeInChunk.toString(), rawAmplitudes.size.toString()))
            }
            Log.i(TAG, getString(R.string.log_finished_extraction_loop_status, rawAmplitudes.size.toString(), totalPcmSamplesProcessed.toString(), iterations.toString()))

        } catch (e: FileNotFoundException) {
            Log.e(TAG, getString(R.string.log_filenotfoundexception_amplitude_extraction, audioUri.toString(), e.message.toString()), e)
            rawAmplitudes.clear()
        } catch (e: IOException) {
            Log.e(TAG, getString(R.string.log_ioexception_amplitude_extraction, audioUri.toString(), e.message.toString()), e)
            rawAmplitudes.clear()
        } catch (e: SecurityException) {
            Log.e(TAG, getString(R.string.log_securityexception_amplitude_extraction, audioUri.toString(), e.message.toString()), e)
            rawAmplitudes.clear()
        } catch (e: IllegalStateException) {
            Log.e(TAG, getString(R.string.log_illegalstateexception_amplitude_extraction, audioUri.toString(), e.message.toString()), e)
            rawAmplitudes.clear()
        } catch (e: Exception) {
            Log.e(TAG, getString(R.string.log_critical_error_amplitude_extraction, audioUri.toString(), e.message.toString()), e)
            rawAmplitudes.clear()
        } finally {
            try { pfd?.close() } catch (e: IOException) { Log.e(TAG, getString(R.string.log_error_closing_parcel_file_descriptor), e) }
            try { extractor?.release() } catch (e: Exception) { Log.e(TAG, getString(R.string.log_error_releasing_media_extractor), e) }
            try { codec?.stop(); codec?.release() } catch (e: Exception) { Log.e(TAG, getString(R.string.log_error_stopping_releasing_media_codec), e) }
        }

        if (rawAmplitudes.isEmpty()) {
            return emptyList()
        }
        val maxFoundAmplitude = rawAmplitudes.maxOrNull()?.toFloat() ?: 1f
        if (maxFoundAmplitude == 0f) {
            return rawAmplitudes.map { 0f }
        }
        return rawAmplitudes.map { it.toFloat() / maxFoundAmplitude }
    }


    private fun getFileNameFromUri(uri: Uri): String {
        var fileName = getString(R.string.default_audio_filename)
        try {
            requireContext().contentResolver.query(uri, null, null, null, null)?.use {
                if (it.moveToFirst()) {
                    val nameIndex = it.getColumnIndex(OpenableColumns.DISPLAY_NAME)
                    if (nameIndex != -1) it.getString(nameIndex)?.takeIf { str -> str.isNotEmpty() }?.also { name -> fileName = name }
                }
            }
        } catch (e: SecurityException) {
            Log.e(TAG, getString(R.string.log_security_exception_get_filename, uri.toString(), e.message.toString()), e)
            showSafeToast(getString(R.string.error_accessing_file_permission, uri.lastPathSegment ?: getString(R.string.audio_default_name)))
        } catch (e: Exception) {
            Log.e(TAG, getString(R.string.log_error_get_filename, uri.toString(), e.message.toString()), e)
            showSafeToast(getString(R.string.error_getting_filename, e.localizedMessage ?: getString(R.string.unknown_error)))
        }
        return fileName
    }

    private fun getFileSizeFromUri(uri: Uri): Long {
        var fileSize: Long = 0
        try {
            requireContext().contentResolver.query(uri, null, null, null, null)?.use {
                if (it.moveToFirst()) {
                    val sizeIndex = it.getColumnIndex(OpenableColumns.SIZE)
                    if (sizeIndex != -1) fileSize = it.getLong(sizeIndex)
                }
            }
        } catch (e: SecurityException) {
            Log.e(TAG, getString(R.string.log_security_exception_get_filesize, uri.toString(), e.message.toString()), e)
            showSafeToast(getString(R.string.error_accessing_file_permission, uri.lastPathSegment ?: getString(R.string.audio_default_name)))
        } catch (e: Exception) {
            Log.e(TAG, getString(R.string.log_error_get_filesize, uri.toString(), e.message.toString()), e)
            showSafeToast(getString(R.string.error_getting_filesize, e.localizedMessage ?: getString(R.string.unknown_error)))
        }
        return fileSize
    }

    private fun getAudioDuration(uri: Uri): Long? {
        if (!isAdded) return null
        val retriever = MediaMetadataRetriever()
        return try {
            retriever.setDataSource(requireContext(), uri)
            retriever.extractMetadata(MediaMetadataRetriever.METADATA_KEY_DURATION)?.toLongOrNull()
        } catch (e: IllegalArgumentException) {
            Log.e(TAG, getString(R.string.log_illegalargumentexception_get_duration, e.message.toString()), e)
            null
        } catch (e: RuntimeException) {
            Log.e(TAG, getString(R.string.log_runtimeexception_get_duration, e.message.toString()), e)
            null
        } catch (e: Exception) {
            Log.e(TAG, getString(R.string.log_general_error_get_duration, e.message.toString()), e)
            null
        } finally {
            try { retriever.release() } catch (e: IOException) { Log.e(TAG, getString(R.string.log_error_releasing_media_metadata_retriever), e) }
        }
    }

    private fun initializeExoPlayer(uri: Uri, autoPlay: Boolean) {
        if (!isAdded) return
        try {
            if (exoPlayer == null) {
                exoPlayer = ExoPlayer.Builder(requireContext()).build().apply { addListener(playerListener) }
            }
            val mediaItem = MediaItem.Builder().setUri(uri).setMediaId(uri.toString()).build()
            exoPlayer?.setMediaItem(mediaItem)
            exoPlayer?.seekTo(playbackPosition)
            exoPlayer?.playWhenReady = autoPlay
            applyPlaybackSpeed()
            exoPlayer?.prepare()
            updatePlayerUI()
        } catch (e: IllegalStateException) {
            Log.e(TAG, getString(R.string.log_illegalstateexception_init_exoplayer, e.message.toString()), e)
            showSafeToast(getString(R.string.error_playback_failed) + getString(R.string.error_suffix_invalid_state))
        } catch (e: Exception) {
            Log.e(TAG, getString(R.string.log_general_error_init_exoplayer, e.message.toString()), e)
            showSafeToast(getString(R.string.error_playback_failed) + getString(R.string.error_suffix_unknown_error))
        }
    }

    private fun initializeAndPlayAttachedAudio(uri: Uri, autoPlay: Boolean) {
        initializeExoPlayer(uri, autoPlay)
    }

    private fun pausePlayback() {
        try {
            exoPlayer?.pause()
        } catch (e: IllegalStateException) {
            Log.e(TAG, getString(R.string.log_illegalstateexception_pause_exoplayer, e.message.toString()), e)
        }
    }

    private fun deleteAttachedAudio() {
        waveformGenerationJob?.cancel()
        releasePlayer()
        attachedAudioUri = null
        attachedAudioOriginalName = null
        playbackPosition = 0
        playWhenReady = true
        currentSpeedIndex = 1
        updateUIForNoAudio()
        listener?.onAttachedAudioDeleted()
        Log.i(TAG, getString(R.string.log_attached_audio_deleted))
    }

    private fun updateUIForNoAudio() {
        if (_binding == null) return // Añadido para seguridad
        binding.btnSelectAudioFile.visibility = View.VISIBLE
        binding.waveformContainer.visibility = View.GONE
        binding.tvLoadingWaveformIndicator.visibility = View.GONE
        if(::waveformView.isInitialized) waveformView.clearWaveform()

        binding.attachedAudioPlayerSection.visibility = View.GONE
        binding.tvAttachedAudioInfo.text = ""
        binding.seekBarAttachedAudio.progress = 0
        binding.seekBarAttachedAudio.max = 100
        if (::playbackSpeedStrings.isInitialized) { // Asegurar que esté inicializado
            binding.tvPlaybackSpeedAttached.text = playbackSpeedStrings.getOrElse(currentSpeedIndex) { playbackSpeedStrings[0] }
        }
        binding.tvPlayerTimerAttach?.text = getString(R.string.player_timer_default_ss)
        binding.tvPlayerTimerAttach?.visibility = View.GONE
        binding.seekBarAttachedAudio.visibility = View.GONE
    }

    private fun cyclePlaybackSpeed() {
        currentSpeedIndex = (currentSpeedIndex + 1) % playbackSpeeds.size
        binding.tvPlaybackSpeedAttached.text = playbackSpeedStrings[currentSpeedIndex]
    }

    private fun applyPlaybackSpeed() {
        exoPlayer?.let {
            val currentSpeedValue = playbackSpeeds[currentSpeedIndex]
            it.playbackParameters = PlaybackParameters(currentSpeedValue)
        }
    }

    private val playerListener = object : Player.Listener {
        override fun onIsPlayingChanged(isPlaying: Boolean) {
            updatePlayerUI()
            if (isPlaying) {
                if (::runnableUpdateSeekBar.isInitialized) seekBarUpdateHandler.post(runnableUpdateSeekBar)
            } else {
                if (::runnableUpdateSeekBar.isInitialized) seekBarUpdateHandler.removeCallbacks(runnableUpdateSeekBar)
                if (::waveformView.isInitialized && exoPlayer != null && (exoPlayer?.duration ?: 0L) > 0L) {
                    waveformView.updatePlaybackIndicator(exoPlayer!!.currentPosition, exoPlayer!!.duration)
                }
            }
        }

        override fun onPlaybackStateChanged(playbackState: Int) {
            updatePlayerUI()
            if (playbackState == Player.STATE_ENDED) {
                exoPlayer?.seekTo(0)
                exoPlayer?.playWhenReady = false
                if (::waveformView.isInitialized && exoPlayer != null && (exoPlayer?.duration ?: 0L) > 0L) {
                    waveformView.updatePlaybackIndicator(0L, exoPlayer!!.duration)
                }
            }
        }

        override fun onPlayerError(error: PlaybackException) {
            if (!isAdded) return
            val errorMessage = getString(R.string.error_playback_failed_specific, error.localizedMessage ?: error.errorCodeName)
            Log.e(TAG, getString(R.string.log_exoplayer_error, error.errorCodeName, error.localizedMessage.toString()), error)
            showAlertDialog(getString(R.string.error_dialog_title), errorMessage)
            updatePlayerUI()
        }
    }

    private fun formatPlayerTimeSeconds(milliseconds: Long): String {
        if (milliseconds < 0) return "00:00"
        val totalSeconds = TimeUnit.MILLISECONDS.toSeconds(milliseconds.coerceAtLeast(0))
        val minutes = TimeUnit.SECONDS.toMinutes(totalSeconds)
        val seconds = totalSeconds - TimeUnit.MINUTES.toSeconds(minutes)
        return String.format(Locale.getDefault(), "%02d:%02d", minutes, seconds)
    }

    private fun updatePlayerTimerDisplay() {
        if (_binding == null || exoPlayer == null) {
            _binding?.tvPlayerTimerAttach?.text = getString(R.string.player_timer_default_ss) // Usar _binding seguro
            return
        }
        val currentPos = exoPlayer?.currentPosition ?: 0
        val totalDur = exoPlayer?.duration ?: 0

        val currentFormatted = formatPlayerTimeSeconds(currentPos)
        val totalFormatted = formatPlayerTimeSeconds(if (totalDur > 0 && totalDur != com.google.android.exoplayer2.C.TIME_UNSET) totalDur else 0)

        binding.tvPlayerTimerAttach?.text = "$currentFormatted / $totalFormatted"
    }

    private fun updatePlayerUI() {
        if (_binding == null) return

        val isPlayerActuallyReady = exoPlayer != null &&
                exoPlayer?.playbackState != Player.STATE_IDLE &&
                exoPlayer?.playbackState != Player.STATE_BUFFERING &&
                (exoPlayer?.duration ?: 0) > 0 &&
                exoPlayer?.duration != com.google.android.exoplayer2.C.TIME_UNSET

        val isPlaying = exoPlayer?.isPlaying ?: false

        binding.btnPlayAttachedAudio.visibility = if (isPlaying) View.GONE else View.VISIBLE
        binding.btnPauseAttachedAudio.visibility = if (isPlaying) View.VISIBLE else View.GONE

        binding.btnPlayAttachedAudio.isEnabled = isPlayerActuallyReady && !isPlaying
        binding.btnPauseAttachedAudio.isEnabled = isPlayerActuallyReady && isPlaying
        binding.tvPlaybackSpeedAttached.isEnabled = isPlayerActuallyReady

        if (isPlayerActuallyReady) {
            binding.seekBarAttachedAudio.visibility = View.VISIBLE
            binding.tvPlayerTimerAttach?.visibility = View.VISIBLE
            updatePlayerTimerDisplay()
            val duration = exoPlayer!!.duration
            binding.seekBarAttachedAudio.max = duration.toInt()
            binding.seekBarAttachedAudio.progress = exoPlayer!!.currentPosition.toInt()
        } else {
            binding.seekBarAttachedAudio.visibility = View.GONE
            binding.tvPlayerTimerAttach?.text = getString(R.string.player_timer_default_ss)
            binding.tvPlayerTimerAttach?.visibility = if (attachedAudioUri != null) View.VISIBLE else View.GONE
            binding.seekBarAttachedAudio.progress = 0
            binding.seekBarAttachedAudio.max = 100
        }
        if (::playbackSpeedStrings.isInitialized && playbackSpeedStrings.isNotEmpty()) {
            binding.tvPlaybackSpeedAttached.text = playbackSpeedStrings.getOrElse(currentSpeedIndex) { playbackSpeedStrings[0] }
        }
    }

    private fun initializeSeekBarUpdater() {
        runnableUpdateSeekBar = object : Runnable {
            override fun run() {
                exoPlayer?.let { player ->
                    if (player.isPlaying && view != null && isAdded) {
                        val currentPosition = player.currentPosition
                        val duration = player.duration
                        if (_binding != null) { // Comprobar _binding antes de usarlo
                            binding.seekBarAttachedAudio.progress = currentPosition.toInt()
                            updatePlayerTimerDisplay()
                        }

                        if (::waveformView.isInitialized && duration > 0) {
                            waveformView.updatePlaybackIndicator(currentPosition, duration)
                        }
                        seekBarUpdateHandler.postDelayed(this, 200)
                    }
                }
            }
        }
    }

    override fun onResume() {
        super.onResume()
        if (attachedAudioUri != null) {
            if (exoPlayer == null) {
                initializeExoPlayer(attachedAudioUri!!, playWhenReady)
            } else {
                exoPlayer?.seekTo(playbackPosition)
                if (playWhenReady && exoPlayer?.playbackState != Player.STATE_ENDED) {
                    exoPlayer?.play()
                }
            }
            updatePlayerUI()
        }
    }

    private fun releasePlayer() {
        if (::runnableUpdateSeekBar.isInitialized) seekBarUpdateHandler.removeCallbacks(runnableUpdateSeekBar)
        try {
            exoPlayer?.release()
        } catch (e: Exception) {
            Log.e(TAG, getString(R.string.log_error_releasing_exoplayer), e)
        }
        exoPlayer = null
    }

    override fun onDestroyView() {
        super.onDestroyView()
        waveformGenerationJob?.cancel()
        releasePlayer()
        currentToast?.cancel()
        _binding = null
    }

    override fun onDetach() {
        super.onDetach()
        listener = null
    }

    fun getAttachedAudioUri(): Uri? = attachedAudioUri
    fun getAttachedAudioOriginalName(): String? = attachedAudioOriginalName

    fun resetState() {
        deleteAttachedAudio()
    }

    private fun showSafeToast(message: String, duration: Int = Toast.LENGTH_SHORT) {
        if(isAdded && context != null) {
            currentToast?.cancel()
            currentToast = Toast.makeText(requireContext(), message, duration)
            currentToast?.show()
        }
    }

    private fun showAlertDialog(title: String, message: String) {
        if (!isAdded) return
        AlertDialog.Builder(requireContext())
            .setTitle(title)
            .setMessage(message)
            .setPositiveButton(getString(R.string.dialog_ok), null)
            .show()
    }

    override fun onWaveformSeek(progressRatio: Float) {
        if (!isAdded || exoPlayer == null || (exoPlayer?.duration ?: 0L) <= 0L || _binding == null) {
            return
        }

        val duration = exoPlayer!!.duration
        val newPosition = (progressRatio * duration).toLong()

        try {
            exoPlayer?.seekTo(newPosition)
            waveformView.updatePlaybackIndicator(newPosition, duration)
            binding.seekBarAttachedAudio.progress = newPosition.toInt()
            updatePlayerTimerDisplay()
        } catch (e: IllegalStateException) {
            Log.e(TAG, getString(R.string.log_illegalstateexception_waveform_seek, e.message.toString()), e)
        }
    }
}